=================config=================
add_bc_loss: 0
batch_size: 256
bc_policy: release/model/robomimic/can/model0.pt
discount: 0.99
end_on_success: 1
env_reward_scale: 1
episode_length: 200
freeze_bc_replay: 1
image_size: 224
load_policy_only: 1
load_pretrained_agent: ''
log_per_step: 5000
mix_rl_rate: 1
mp_eval: 1
nstep: 3
num_critic_update: 1
num_eval_episode: 50
num_train_step: 200000
num_warm_up_episode: 20
obs_stack: 1
preload_datapath: release/data/robomimic/can/processed_data96.hdf5
preload_num_data: 10
pretrain_epoch_len: 10000
pretrain_num_epoch: 0
pretrain_only: 1
prop_stack: 3
q_agent:
  act_method: ibrl
  actor:
    dropout: 0.5
    feature_dim: 128
    hidden_dim: 1024
    max_action_norm: -1
    orth: 1
    spatial_emb: 0
  bc_loss_coef: 0.1
  bc_loss_dynamic: 0
  bootstrap_method: ibrl
  critic:
    drop: 0
    feature_dim: 128
    fuse_patch: 1
    hidden_dim: 1024
    norm_weight: 0
    orth: 1
    spatial_emb: 1024
  critic_target_tau: 0.01
  device: cuda
  enc_type: vit
  ibrl_eps_greedy: 1
  lr: 0.0001
  resnet:
    downsample: default
    norm_layer: gnn
    shallow: 0
    stem: default
  resnet96:
    shallow: 0
    use_1x1: 0
  soft_ibrl_beta: 10
  state_actor:
    dropout: 0.5
    hidden_dim: 512
    layer_norm: 0
    num_layer: 3
    orth: 0
  state_critic:
    append_action: 0
    dropout: 0.0
    hidden_dim: 512
    layer_norm: 0
    num_k: 2
    num_layer: 3
    num_q: 10
    orth: 0
  stddev_clip: 0.3
  use_prop: 1
  vit:
    depth: 1
    embed_dim: 128
    embed_norm: 0
    embed_style: embed2
    num_heads: 4
    patch_size: 8
    stride: -1
replay_buffer_size: 1000
rl_camera: robot0_eye_in_hand
rl_image_size: 96
save_dir: exps/rl/run1
save_per_success: -1
seed: 1
state_stack: 1
stddev_max: 0.1
stddev_min: 0.1
stddev_step: 500000
task_name: PickPlaceCan
update_freq: 2
use_state: 0
use_wb: 0
========================================
rl_cameras: ['robot0_eye_in_hand']
(3, 96, 96)
encoder output dim:  15488
patch output dim:  128
============encoder weights=============
VitEncoder(
  (vit): MinVit(
    (patch_embed): PatchEmbed2(
      (embed): Sequential(
        (0): Conv2d(3, 128, kernel_size=(8, 8), stride=(4, 4))
        (1): Identity()
        (2): ReLU()
        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))
      )
    )
    (net): Sequential(
      (0): TransformerLayer(
        (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (mha): MultiHeadAttention(
          (qkv_proj): Linear(in_features=128, out_features=384, bias=True)
          (out_proj): Linear(in_features=128, out_features=128, bias=True)
        )
        (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (linear1): Linear(in_features=128, out_features=512, bias=True)
        (linear2): Linear(in_features=512, out_features=128, bias=True)
        (dropout): Dropout(p=0, inplace=False)
      )
    )
    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
  )
)
| Module                         |   #Params |      % |
|--------------------------------+-----------+--------|
| vit.pos_embed                  |    15,488 |   4.01 |
| vit.patch_embed.embed.0.weight |    24,576 |   6.36 |
| vit.patch_embed.embed.0.bias   |       128 |   0.03 |
| vit.patch_embed.embed.3.weight |   147,456 |  38.17 |
| vit.patch_embed.embed.3.bias   |       128 |   0.03 |
| vit.net.0.layer_norm1.weight   |       128 |   0.03 |
| vit.net.0.layer_norm1.bias     |       128 |   0.03 |
| vit.net.0.mha.qkv_proj.weight  |    49,152 |  12.72 |
| vit.net.0.mha.qkv_proj.bias    |       384 |   0.10 |
| vit.net.0.mha.out_proj.weight  |    16,384 |   4.24 |
| vit.net.0.mha.out_proj.bias    |       128 |   0.03 |
| vit.net.0.layer_norm2.weight   |       128 |   0.03 |
| vit.net.0.layer_norm2.bias     |       128 |   0.03 |
| vit.net.0.linear1.weight       |    65,536 |  16.96 |
| vit.net.0.linear1.bias         |       512 |   0.13 |
| vit.net.0.linear2.weight       |    65,536 |  16.96 |
| vit.net.0.linear2.bias         |       128 |   0.03 |
| vit.norm.weight                |       128 |   0.03 |
| vit.norm.bias                  |       128 |   0.03 |
| Total                          |   386,304 | 100.00 |
=============critic weights=============
Critic(
  (q1): SpatialEmbQNet(
    weight: nn.Parameter (torch.Size([1, 128, 1024]))
    (input_proj): Sequential(
      (0): Linear(in_features=155, out_features=1024, bias=True)
      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (2): ReLU(inplace=True)
    )
    (q): Sequential(
      (0): Linear(in_features=1058, out_features=1024, bias=True)
      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (2): ReLU(inplace=True)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (5): ReLU(inplace=True)
      (6): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
  (q2): SpatialEmbQNet(
    weight: nn.Parameter (torch.Size([1, 128, 1024]))
    (input_proj): Sequential(
      (0): Linear(in_features=155, out_features=1024, bias=True)
      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (2): ReLU(inplace=True)
    )
    (q): Sequential(
      (0): Linear(in_features=1058, out_features=1024, bias=True)
      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (2): ReLU(inplace=True)
      (3): Linear(in_features=1024, out_features=1024, bias=True)
      (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (5): ReLU(inplace=True)
      (6): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
)
| Module                 |   #Params |      % |
|------------------------+-----------+--------|
| q1.weight              |   131,072 |   2.69 |
| q1.input_proj.0.weight |   158,720 |   3.26 |
| q1.input_proj.0.bias   |     1,024 |   0.02 |
| q1.input_proj.1.weight |     1,024 |   0.02 |
| q1.input_proj.1.bias   |     1,024 |   0.02 |
| q1.q.0.weight          | 1,083,392 |  22.27 |
| q1.q.0.bias            |     1,024 |   0.02 |
| q1.q.1.weight          |     1,024 |   0.02 |
| q1.q.1.bias            |     1,024 |   0.02 |
| q1.q.3.weight          | 1,048,576 |  21.56 |
| q1.q.3.bias            |     1,024 |   0.02 |
| q1.q.4.weight          |     1,024 |   0.02 |
| q1.q.4.bias            |     1,024 |   0.02 |
| q1.q.6.weight          |     1,024 |   0.02 |
| q1.q.6.bias            |         1 |   0.00 |
| q2.weight              |   131,072 |   2.69 |
| q2.input_proj.0.weight |   158,720 |   3.26 |
| q2.input_proj.0.bias   |     1,024 |   0.02 |
| q2.input_proj.1.weight |     1,024 |   0.02 |
| q2.input_proj.1.bias   |     1,024 |   0.02 |
| q2.q.0.weight          | 1,083,392 |  22.27 |
| q2.q.0.bias            |     1,024 |   0.02 |
| q2.q.1.weight          |     1,024 |   0.02 |
| q2.q.1.bias            |     1,024 |   0.02 |
| q2.q.3.weight          | 1,048,576 |  21.56 |
| q2.q.3.bias            |     1,024 |   0.02 |
| q2.q.4.weight          |     1,024 |   0.02 |
| q2.q.4.bias            |     1,024 |   0.02 |
| q2.q.6.weight          |     1,024 |   0.02 |
| q2.q.6.bias            |         1 |   0.00 |
| Total                  | 4,864,002 | 100.00 |
=============actor weights==============
Actor(
  (compress): Sequential(
    (0): Linear(in_features=15488, out_features=128, bias=True)
    (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): ReLU()
  )
  (policy): Sequential(
    (0): Linear(in_features=155, out_features=1024, bias=True)
    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=1024, out_features=1024, bias=True)
    (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (6): Dropout(p=0.5, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=1024, out_features=7, bias=True)
    (9): Tanh()
  )
)
| Module            |   #Params |      % |
|-------------------+-----------+--------|
| compress.0.weight | 1,982,464 |  61.89 |
| compress.0.bias   |       128 |   0.00 |
| compress.1.weight |       128 |   0.00 |
| compress.1.bias   |       128 |   0.00 |
| policy.0.weight   |   158,720 |   4.95 |
| policy.0.bias     |     1,024 |   0.03 |
| policy.1.weight   |     1,024 |   0.03 |
| policy.1.bias     |     1,024 |   0.03 |
| policy.4.weight   | 1,048,576 |  32.73 |
| policy.4.bias     |     1,024 |   0.03 |
| policy.5.weight   |     1,024 |   0.03 |
| policy.5.bias     |     1,024 |   0.03 |
| policy.8.weight   |     7,168 |   0.22 |
| policy.8.bias     |         7 |   0.00 |
| Total             | 3,203,463 | 100.00 |
=========config of loaded agent=========
batch_size: 256
dataset:
  eval_episode_len: 300
  max_len: -1
  norm_action: 0
  num_data: 10
  obs_stack: 1
  path: data/robomimic/can/processed_data96.hdf5
  prop_stack: 1
  rl_camera: robot0_eye_in_hand
  use_state: 0
epoch_len: 10000
grad_clip: 5
image_size: 224
load_model: none
lr: 0.0001
num_epoch: 10
num_eval_episode: 50
policy:
  dropout: 0
  encoder:
    feat_dim: 512
    resnet:
      downsample: default
      norm_layer: gnn
      shallow: 0
      stem: default
  hidden_dim: 1024
  num_layer: 1
  orth_init: 0
  use_prop: 0
rl_image_size: 96
robots:
- Panda
save_dir: exps2/bc/can1/stemdefault_seed3
seed: 3
state_policy:
  dropout: 0.5
  hidden_dim: 256
  layer_norm: 0
  num_layer: 3
task_name: PickPlaceCan
use_wb: 1
weight_decay: 0
========================================
obs_stack: 1, observation shape: (3, 96, 96)
observation shape:  (3, 96, 96)
norm layer: gnn
loading first 10 episodes from release/data/robomimic/can/processed_data96.hdf5
Raw Dataset size (#episode): 10
episode 0 length: 118
episode 1 length: 118
episode 2 length: 113
episode 3 length: 98
episode 4 length: 102
episode 5 length: 134
episode 6 length: 115
episode 7 length: 115
episode 8 length: 127
episode 9 length: 120
Size of the replay buffer: 10, # success: 10
demo actions shape: (1160, 7)
demo action norm: mean: 0.7647, max: 1.6232
Warm up done. #episode: 20
#episode from warmup: 10, #reward: 4.0
Saved model to exps/rl/run1/model0.pt
[5000] Time spent = 720.53 s
5000: eval/seed           : 50
5000: other/elapsed_time  : 464.24
5000: other/episode       : 25
5000: other/replay        : 45
5000: other/speed         : 10.77
5000: other/step          : 5000
5000: other/train_step    : 2499
5000: score/num_success   : 14
5000: score/score         : 0.00
5000: actor/anorm_bc      [ 5000]: avg:   0.5100, min:   0.0174[ 246], max:   1.3150[2204]
5000: actor/anorm_rl      [ 5000]: avg:   1.8654, min:   0.1835[4474], max:   2.4495[ 303]
5000: actor/bc_eval       [10000]: avg:   0.5623, min:   0.0000[   1], max:   7.0000[3046]
5000: actor/bc_train      [ 5000]: avg:   0.4812, min:   0.0000[   1], max:   1.0000[   5]
5000: actor/bootstrap_bc  [ 2499]: avg:   0.2744, min:   0.0625[  61], max:   0.5586[ 220]
5000: data/batch_R        [ 2499]: avg:   0.0085, min:   0.0000[   9], max:   0.0348[ 783]
5000: data/discount       [ 2499]: avg:   0.9523, min:   0.9134[ 783], max:   0.9703[ 234]
5000: data/episode_len    [   25]: avg: 200.0000, min: 200.0000[   1], max: 200.0000[   1]
5000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  17], max:   0.1000[   2]
5000: score/train_score   [   25]: avg:   0.0000, min:   0.0000[   1], max:   0.0000[   1]
5000: train/actor_loss    [ 2499]: avg:  -0.2635, min:  -0.3517[1856], max:   1.4668[   3]
5000: train/critic_loss   [ 2499]: avg:   0.0114, min:   0.0011[2279], max:   5.3444[   2]
5000: train/critic_qt     [ 2499]: avg:   0.2648, min:  -0.6569[   4], max:   0.3385[1776]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| act      |  5000 |           6.3 |   4.8 |
| env step |  5000 |          23.1 |  17.6 |
| add      |  5000 |           0.1 |   0.1 |
| train    |  2499 |         110.7 |  42.1 |
| reset    |    25 |        1539.7 |   5.9 |
| eval     |     1 |      193643   |  29.5 |
| total(s) |     1 |         656.3 | 100   |
total time: 0:10:58
Mem info: used: 7.777 GB, avail: 126.901 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[10000] Time spent = 660.59 s
10000: eval/seed           : 100
10000: other/elapsed_time  : 463.74
10000: other/episode       : 50
10000: other/replay        : 70
10000: other/speed         : 10.78
10000: other/step          : 10000
10000: other/train_step    : 4999
10000: score/num_success   : 14
10000: score/score         : 0.00
10000: actor/anorm_bc      [ 5000]: avg:   0.5007, min:   0.0315[2997], max:   1.3539[ 178]
10000: actor/anorm_rl      [ 5000]: avg:   1.0004, min:   0.1485[3544], max:   2.3811[2198]
10000: actor/bc_eval       [10000]: avg:   0.2299, min:   0.0000[   3], max:   4.0000[ 512]
10000: actor/bc_train      [ 5000]: avg:   0.4658, min:   0.0000[   1], max:   1.0000[  10]
10000: actor/bootstrap_bc  [ 2500]: avg:   0.2479, min:   0.1484[1451], max:   0.3398[ 168]
10000: data/batch_R        [ 2500]: avg:   0.0042, min:   0.0000[   2], max:   0.0232[ 312]
10000: data/discount       [ 2500]: avg:   0.9541, min:   0.9248[1313], max:   0.9703[   7]
10000: data/episode_len    [   25]: avg: 200.0000, min: 200.0000[   1], max: 200.0000[   1]
10000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[   2]
10000: score/train_score   [   25]: avg:   0.0000, min:   0.0000[   1], max:   0.0000[   1]
10000: train/actor_loss    [ 2500]: avg:  -0.2652, min:  -0.3368[  16], max:  -0.1985[2404]
10000: train/critic_loss   [ 2500]: avg:   0.0018, min:   0.0007[2486], max:   0.0049[ 192]
10000: train/critic_qt     [ 2500]: avg:   0.2625, min:   0.2123[2408], max:   0.3281[  16]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.4 |  41.4 |
| act      |  5000 |           6.4 |   4.8 |
| env step |  5000 |          23.8 |  18   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    25 |        1545.7 |   5.9 |
| eval     |     1 |      196518   |  29.8 |
| total(s) |     1 |         660.1 | 100   |
total time: 0:21:58
Mem info: used: 7.811 GB, avail: 126.818 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[15000] Time spent = 660.99 s
15000: eval/seed           : 150
15000: other/elapsed_time  : 466.17
15000: other/episode       : 75
15000: other/replay        : 95
15000: other/speed         : 10.73
15000: other/step          : 15000
15000: other/train_step    : 7499
15000: score/num_success   : 16
15000: score/score         : 0.00
15000: actor/anorm_bc      [ 5000]: avg:   0.5299, min:   0.0430[1652], max:   1.4406[1454]
15000: actor/anorm_rl      [ 5000]: avg:   0.9176, min:   0.1505[ 574], max:   2.0772[3024]
15000: actor/bc_eval       [10000]: avg:   0.3562, min:   0.0000[   1], max:   5.0000[ 296]
15000: actor/bc_train      [ 5000]: avg:   0.4772, min:   0.0000[   1], max:   1.0000[   6]
15000: actor/bootstrap_bc  [ 2500]: avg:   0.2320, min:   0.1367[2036], max:   0.3320[ 599]
15000: data/batch_R        [ 2500]: avg:   0.0029, min:   0.0000[   2], max:   0.0194[1448]
15000: data/discount       [ 2500]: avg:   0.9547, min:   0.9286[ 478], max:   0.9703[  60]
15000: data/episode_len    [   25]: avg: 197.0400, min: 137.0000[   8], max: 200.0000[   1]
15000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[   4]
15000: score/train_score   [   25]: avg:   0.0800, min:   0.0000[   1], max:   1.0000[   8]
15000: train/actor_loss    [ 2500]: avg:  -0.2150, min:  -0.2757[ 114], max:  -0.1634[2375]
15000: train/critic_loss   [ 2500]: avg:   0.0013, min:   0.0006[2447], max:   0.0041[1539]
15000: train/critic_qt     [ 2500]: avg:   0.2130, min:   0.1725[2400], max:   0.2652[ 114]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.6 |  41.5 |
| act      |  5000 |           6.4 |   4.8 |
| env step |  5000 |          24.1 |  18.3 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    25 |        1553.9 |   5.9 |
| eval     |     1 |      194506   |  29.4 |
| total(s) |     1 |         660.5 | 100   |
total time: 0:32:59
Mem info: used: 7.811 GB, avail: 126.793 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[20000] Time spent = 653.02 s
20000: eval/seed           : 200
20000: other/elapsed_time  : 461.85
20000: other/episode       : 100
20000: other/replay        : 120
20000: other/speed         : 10.83
20000: other/step          : 20000
20000: other/train_step    : 9999
20000: score/num_success   : 16
20000: score/score         : 0.00
20000: actor/anorm_bc      [ 5000]: avg:   0.4463, min:   0.0264[2420], max:   1.5145[1244]
20000: actor/anorm_rl      [ 5000]: avg:   1.0030, min:   0.1178[4774], max:   2.0982[ 436]
20000: actor/bc_eval       [10000]: avg:   0.4004, min:   0.0000[   1], max:   7.0000[3139]
20000: actor/bc_train      [ 5000]: avg:   0.4926, min:   0.0000[   2], max:   1.0000[   1]
20000: actor/bootstrap_bc  [ 2500]: avg:   0.2387, min:   0.1406[ 164], max:   0.3477[1729]
20000: data/batch_R        [ 2500]: avg:   0.0023, min:   0.0000[   1], max:   0.0194[ 340]
20000: data/discount       [ 2500]: avg:   0.9552, min:   0.9248[1122], max:   0.9703[   5]
20000: data/episode_len    [   25]: avg: 200.0000, min: 200.0000[   1], max: 200.0000[   1]
20000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[   4]
20000: score/train_score   [   25]: avg:   0.0000, min:   0.0000[   1], max:   0.0000[   1]
20000: train/actor_loss    [ 2500]: avg:  -0.1813, min:  -0.2338[ 110], max:  -0.1350[2393]
20000: train/critic_loss   [ 2500]: avg:   0.0010, min:   0.0005[1799], max:   0.0049[2109]
20000: train/critic_qt     [ 2500]: avg:   0.1799, min:   0.1341[2122], max:   0.2231[ 360]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.5 |  41.9 |
| act      |  5000 |           6.3 |   4.8 |
| env step |  5000 |          23.4 |  18   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    25 |        1547.7 |   5.9 |
| eval     |     1 |      190816   |  29.2 |
| total(s) |     1 |         652.5 | 100   |
total time: 0:43:52
Mem info: used: 7.811 GB, avail: 126.787 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[25000] Time spent = 656.78 s
25000: eval/seed           : 250
25000: other/elapsed_time  : 465.17
25000: other/episode       : 126
25000: other/replay        : 146
25000: other/speed         : 10.75
25000: other/step          : 25000
25000: other/train_step    : 12499
25000: score/num_success   : 20
25000: score/score         : 0.00
25000: actor/anorm_bc      [ 5000]: avg:   0.4788, min:   0.0273[3784], max:   1.4538[1006]
25000: actor/anorm_rl      [ 5000]: avg:   1.0112, min:   0.1358[3878], max:   2.3792[2294]
25000: actor/bc_eval       [10000]: avg:   0.4183, min:   0.0000[   1], max:   6.0000[ 850]
25000: actor/bc_train      [ 5000]: avg:   0.4180, min:   0.0000[   2], max:   1.0000[   1]
25000: actor/bootstrap_bc  [ 2500]: avg:   0.2471, min:   0.1445[ 664], max:   0.3555[ 252]
25000: data/batch_R        [ 2500]: avg:   0.0020, min:   0.0000[   1], max:   0.0155[ 393]
25000: data/discount       [ 2500]: avg:   0.9550, min:   0.9210[1121], max:   0.9703[ 186]
25000: data/episode_len    [   26]: avg: 187.9615, min: 101.0000[  24], max: 200.0000[   1]
25000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[  11]
25000: score/train_score   [   26]: avg:   0.1538, min:   0.0000[   1], max:   1.0000[   6]
25000: train/actor_loss    [ 2500]: avg:  -0.1607, min:  -0.2070[ 308], max:  -0.1177[2023]
25000: train/critic_loss   [ 2500]: avg:   0.0010, min:   0.0005[1787], max:   0.0050[ 254]
25000: train/critic_qt     [ 2500]: avg:   0.1598, min:   0.1250[1832], max:   0.2120[ 581]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.5 |  41.7 |
| act      |  5000 |           6.3 |   4.8 |
| env step |  5000 |          23.8 |  18.1 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    26 |        1538.8 |   6.1 |
| eval     |     1 |      191303   |  29.1 |
| total(s) |     1 |         656.3 | 100   |
total time: 0:54:49
Mem info: used: 7.811 GB, avail: 126.744 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[30000] Time spent = 645.88 s
30000: eval/seed           : 300
30000: other/elapsed_time  : 465.05
30000: other/episode       : 152
30000: other/replay        : 172
30000: other/speed         : 10.75
30000: other/step          : 30000
30000: other/train_step    : 14999
30000: score/num_success   : 22
30000: score/score         : 0.26
30000: actor/anorm_bc      [ 5000]: avg:   0.4589, min:   0.0292[3991], max:   1.4573[  57]
30000: actor/anorm_rl      [ 5000]: avg:   0.9275, min:   0.0957[4786], max:   2.2644[4329]
30000: actor/bc_eval       [ 8962]: avg:   0.3792, min:   0.0000[   2], max:   6.0000[1618]
30000: actor/bc_train      [ 5000]: avg:   0.4476, min:   0.0000[   8], max:   1.0000[   1]
30000: actor/bootstrap_bc  [ 2500]: avg:   0.2524, min:   0.1602[ 495], max:   0.3438[ 445]
30000: data/batch_R        [ 2500]: avg:   0.0021, min:   0.0000[   6], max:   0.0155[ 567]
30000: data/discount       [ 2500]: avg:   0.9549, min:   0.9248[ 603], max:   0.9703[  68]
30000: data/episode_len    [   26]: avg: 196.9615, min: 127.0000[  10], max: 200.0000[   1]
30000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  26], max:   0.1000[  11]
30000: score/train_score   [   26]: avg:   0.0769, min:   0.0000[   1], max:   1.0000[  10]
30000: train/actor_loss    [ 2500]: avg:  -0.1567, min:  -0.2112[   3], max:  -0.1142[ 982]
30000: train/critic_loss   [ 2500]: avg:   0.0010, min:   0.0005[1404], max:   0.0061[1913]
30000: train/critic_qt     [ 2500]: avg:   0.1554, min:   0.1191[2324], max:   0.1982[   3]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.4 |  42.4 |
| act      |  5000 |           6.4 |   4.9 |
| env step |  5000 |          23.7 |  18.4 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    26 |        1551.9 |   6.3 |
| eval     |     1 |      180545   |  28   |
| total(s) |     1 |         645.4 | 100   |
total time: 1:05:35
Mem info: used: 7.811 GB, avail: 126.786 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[35000] Time spent = 646.77 s
35000: eval/seed           : 350
35000: other/elapsed_time  : 472.95
35000: other/episode       : 183
35000: other/replay        : 203
35000: other/speed         : 10.57
35000: other/step          : 35000
35000: other/train_step    : 17499
35000: score/num_success   : 37
35000: score/score         : 0.44
35000: actor/anorm_bc      [ 5000]: avg:   0.5294, min:   0.0251[ 939], max:   1.5968[1371]
35000: actor/anorm_rl      [ 5000]: avg:   0.9871, min:   0.0770[ 982], max:   2.2638[4840]
35000: actor/bc_eval       [ 7776]: avg:   0.3717, min:   0.0000[   1], max:   4.0000[ 348]
35000: actor/bc_train      [ 5000]: avg:   0.4860, min:   0.0000[   1], max:   1.0000[  22]
35000: actor/bootstrap_bc  [ 2500]: avg:   0.2556, min:   0.1523[  12], max:   0.3594[1464]
35000: data/batch_R        [ 2500]: avg:   0.0022, min:   0.0000[   1], max:   0.0194[2010]
35000: data/discount       [ 2500]: avg:   0.9549, min:   0.9248[1398], max:   0.9703[ 143]
35000: data/episode_len    [   31]: avg: 161.6129, min:  83.0000[  28], max: 200.0000[   1]
35000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  16], max:   0.1000[   3]
35000: score/train_score   [   31]: avg:   0.4839, min:   0.0000[   1], max:   1.0000[   5]
35000: train/actor_loss    [ 2500]: avg:  -0.1557, min:  -0.2029[2422], max:  -0.1159[1269]
35000: train/critic_loss   [ 2500]: avg:   0.0010, min:   0.0004[1378], max:   0.0062[2432]
35000: train/critic_qt     [ 2500]: avg:   0.1546, min:   0.1190[1440], max:   0.1972[2344]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.3 |  42.3 |
| act      |  5000 |           6.4 |   4.9 |
| env step |  5000 |          24   |  18.5 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    31 |        1530.2 |   7.3 |
| eval     |     1 |      173528   |  26.8 |
| total(s) |     1 |         646.3 | 100   |
total time: 1:16:22
Mem info: used: 7.811 GB, avail: 126.765 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[40000] Time spent = 618.64 s
40000: eval/seed           : 400
40000: other/elapsed_time  : 469.88
40000: other/episode       : 213
40000: other/replay        : 233
40000: other/speed         : 10.64
40000: other/step          : 40000
40000: other/train_step    : 19999
40000: score/num_success   : 48
40000: score/score         : 0.50
40000: actor/anorm_bc      [ 5000]: avg:   0.5543, min:   0.0560[ 265], max:   1.4860[2115]
40000: actor/anorm_rl      [ 5000]: avg:   1.0344, min:   0.1596[4803], max:   2.2827[3016]
40000: actor/bc_eval       [ 7392]: avg:   0.2932, min:   0.0000[   1], max:   5.0000[4617]
40000: actor/bc_train      [ 5000]: avg:   0.3916, min:   0.0000[  16], max:   1.0000[   1]
40000: actor/bootstrap_bc  [ 2500]: avg:   0.2262, min:   0.1250[2486], max:   0.3438[ 197]
40000: data/batch_R        [ 2500]: avg:   0.0030, min:   0.0000[   2], max:   0.0194[1401]
40000: data/discount       [ 2500]: avg:   0.9546, min:   0.9286[ 595], max:   0.9703[  29]
40000: data/episode_len    [   30]: avg: 166.3667, min:  82.0000[  24], max: 200.0000[   3]
40000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  16], max:   0.1000[   3]
40000: score/train_score   [   30]: avg:   0.3667, min:   0.0000[   3], max:   1.0000[   1]
40000: train/actor_loss    [ 2500]: avg:  -0.1807, min:  -0.2426[2400], max:  -0.1210[ 719]
40000: train/critic_loss   [ 2500]: avg:   0.0011, min:   0.0005[ 156], max:   0.0054[2499]
40000: train/critic_qt     [ 2500]: avg:   0.1779, min:   0.1230[ 719], max:   0.2298[2478]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.3 |  44.2 |
| act      |  5000 |           6.3 |   5.1 |
| env step |  5000 |          23.6 |  19.1 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    30 |        1541   |   7.5 |
| eval     |     1 |      148400   |  24   |
| total(s) |     1 |         618.1 | 100   |
total time: 1:26:40
Mem info: used: 7.811 GB, avail: 126.751 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[45000] Time spent = 621.55 s
45000: eval/seed           : 450
45000: other/elapsed_time  : 479.30
45000: other/episode       : 249
45000: other/replay        : 269
45000: other/speed         : 10.43
45000: other/step          : 45000
45000: other/train_step    : 22499
45000: score/num_success   : 71
45000: score/score         : 0.62
45000: actor/anorm_bc      [ 5000]: avg:   0.6435, min:   0.0190[3741], max:   1.4700[2451]
45000: actor/anorm_rl      [ 5000]: avg:   1.0341, min:   0.1174[2598], max:   2.1327[4183]
45000: actor/bc_eval       [ 6935]: avg:   0.2833, min:   0.0000[   1], max:   5.0000[2299]
45000: actor/bc_train      [ 5000]: avg:   0.3676, min:   0.0000[   2], max:   1.0000[   1]
45000: actor/bootstrap_bc  [ 2500]: avg:   0.1928, min:   0.1133[2466], max:   0.2812[2059]
45000: data/batch_R        [ 2500]: avg:   0.0040, min:   0.0000[   8], max:   0.0270[1881]
45000: data/discount       [ 2500]: avg:   0.9541, min:   0.9172[ 824], max:   0.9703[  37]
45000: data/episode_len    [   36]: avg: 140.4167, min:  78.0000[   9], max: 200.0000[   4]
45000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   6], max:   0.1000[   3]
45000: score/train_score   [   36]: avg:   0.6389, min:   0.0000[   4], max:   1.0000[   1]
45000: train/actor_loss    [ 2500]: avg:  -0.2294, min:  -0.2889[2308], max:  -0.1622[ 679]
45000: train/critic_loss   [ 2500]: avg:   0.0014, min:   0.0006[1847], max:   0.0077[1362]
45000: train/critic_qt     [ 2500]: avg:   0.2247, min:   0.1661[ 679], max:   0.2819[2308]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.4 |  44   |
| act      |  5000 |           6.3 |   5.1 |
| env step |  5000 |          23.6 |  19   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    36 |        1534.5 |   8.9 |
| eval     |     1 |      141927   |  22.9 |
| total(s) |     1 |         621.1 | 100   |
total time: 1:37:02
Mem info: used: 7.811 GB, avail: 126.756 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[50000] Time spent = 654.51 s
50000: eval/seed           : 500
50000: other/elapsed_time  : 491.97
50000: other/episode       : 291
50000: other/replay        : 311
50000: other/speed         : 10.16
50000: other/step          : 50000
50000: other/train_step    : 24999
50000: score/num_success   : 102
50000: score/score         : 0.76
50000: actor/anorm_bc      [ 5000]: avg:   0.6784, min:   0.0298[3706], max:   1.4523[ 516]
50000: actor/anorm_rl      [ 5000]: avg:   1.2105, min:   0.2419[2747], max:   2.4495[4059]
50000: actor/bc_eval       [ 5442]: avg:   0.2969, min:   0.0000[   1], max:   5.0000[2227]
50000: actor/bc_train      [ 5000]: avg:   0.3322, min:   0.0000[   1], max:   1.0000[   4]
50000: actor/bootstrap_bc  [ 2500]: avg:   0.1812, min:   0.1133[  52], max:   0.2734[2483]
50000: data/batch_R        [ 2500]: avg:   0.0051, min:   0.0000[   6], max:   0.0271[2435]
50000: data/discount       [ 2500]: avg:   0.9535, min:   0.9210[ 462], max:   0.9703[  46]
50000: data/episode_len    [   42]: avg: 118.8571, min:  66.0000[  35], max: 200.0000[  16]
50000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   6], max:   0.1000[   3]
50000: score/train_score   [   42]: avg:   0.7381, min:   0.0000[  16], max:   1.0000[   1]
50000: train/actor_loss    [ 2500]: avg:  -0.2901, min:  -0.3568[2452], max:  -0.2219[ 262]
50000: train/critic_loss   [ 2500]: avg:   0.0013, min:   0.0005[2373], max:   0.0041[1090]
50000: train/critic_qt     [ 2500]: avg:   0.2838, min:   0.2173[ 262], max:   0.3465[2350]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         109.6 |  41.9 |
| act      |  5000 |           6.6 |   5   |
| env step |  5000 |          24   |  18.4 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    42 |        1531.2 |   9.8 |
| eval     |     1 |      162215   |  24.8 |
| total(s) |     1 |         654   | 100   |
total time: 1:47:56
Mem info: used: 7.811 GB, avail: 126.763 GB, total: 156.060 GB
[55000] Time spent = 690.38 s
55000: eval/seed           : 550
55000: other/elapsed_time  : 497.28
55000: other/episode       : 335
55000: other/replay        : 355
55000: other/speed         : 10.05
55000: other/step          : 55000
55000: other/train_step    : 27499
55000: score/num_success   : 138
55000: score/score         : 0.62
55000: actor/anorm_bc      [ 5000]: avg:   0.6915, min:   0.0276[  22], max:   1.4915[4135]
55000: actor/anorm_rl      [ 5000]: avg:   1.2331, min:   0.2062[ 615], max:   2.3257[4597]
55000: actor/bc_eval       [ 6359]: avg:   0.2697, min:   0.0000[   1], max:   4.0000[1043]
55000: actor/bc_train      [ 5000]: avg:   0.3346, min:   0.0000[   8], max:   1.0000[   1]
55000: actor/bootstrap_bc  [ 2500]: avg:   0.1973, min:   0.1211[ 118], max:   0.2852[ 116]
55000: data/batch_R        [ 2500]: avg:   0.0062, min:   0.0000[  13], max:   0.0270[2298]
55000: data/discount       [ 2500]: avg:   0.9528, min:   0.9210[1163], max:   0.9703[  18]
55000: data/episode_len    [   44]: avg: 112.1364, min:  59.0000[  43], max: 200.0000[   3]
55000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   6], max:   0.1000[  10]
55000: score/train_score   [   44]: avg:   0.8182, min:   0.0000[   3], max:   1.0000[   1]
55000: train/actor_loss    [ 2500]: avg:  -0.3150, min:  -0.3690[2412], max:  -0.2645[ 725]
55000: train/critic_loss   [ 2500]: avg:   0.0013, min:   0.0006[1059], max:   0.0036[ 202]
55000: train/critic_qt     [ 2500]: avg:   0.3096, min:   0.2658[ 538], max:   0.3622[1063]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         110.3 |  40   |
| act      |  5000 |           6.4 |   4.7 |
| env step |  5000 |          24.2 |  17.6 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    44 |        1530.9 |   9.8 |
| eval     |     1 |      192905   |  28   |
| total(s) |     1 |         690   | 100   |
total time: 1:59:27
Mem info: used: 7.811 GB, avail: 126.439 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[60000] Time spent = 645.88 s
60000: eval/seed           : 600
60000: other/elapsed_time  : 529.95
60000: other/episode       : 379
60000: other/replay        : 399
60000: other/speed         : 9.43
60000: other/step          : 60000
60000: other/train_step    : 29999
60000: score/num_success   : 171
60000: score/score         : 0.84
60000: actor/anorm_bc      [ 5000]: avg:   0.6733, min:   0.0317[2978], max:   1.5030[1954]
60000: actor/anorm_rl      [ 5000]: avg:   1.2451, min:   0.1396[1833], max:   2.2323[1598]
60000: actor/bc_eval       [ 4961]: avg:   0.1990, min:   0.0000[   1], max:   4.0000[ 339]
60000: actor/bc_train      [ 5000]: avg:   0.3052, min:   0.0000[   1], max:   1.0000[  20]
60000: actor/bootstrap_bc  [ 2500]: avg:   0.1935, min:   0.1094[1638], max:   0.2891[1176]
60000: data/batch_R        [ 2500]: avg:   0.0076, min:   0.0000[   5], max:   0.0308[ 506]
60000: data/discount       [ 2500]: avg:   0.9519, min:   0.9172[1197], max:   0.9703[ 191]
60000: data/episode_len    [   44]: avg: 113.0000, min:  52.0000[  39], max: 200.0000[   9]
60000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  35], max:   0.1000[  10]
60000: score/train_score   [   44]: avg:   0.7500, min:   0.0000[   9], max:   1.0000[   1]
60000: train/actor_loss    [ 2500]: avg:  -0.3319, min:  -0.3874[ 650], max:  -0.2858[1655]
60000: train/critic_loss   [ 2500]: avg:   0.0012, min:   0.0005[ 667], max:   0.0047[2031]
60000: train/critic_qt     [ 2500]: avg:   0.3263, min:   0.2819[ 136], max:   0.3832[ 650]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         113.1 |  43.8 |
| act      |  5000 |           7.4 |   5.7 |
| env step |  5000 |          27.5 |  21.3 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    44 |        1630.3 |  11.1 |
| eval     |     1 |      115620   |  17.9 |
| total(s) |     1 |         645.4 | 100   |
total time: 2:10:13
Mem info: used: 7.811 GB, avail: 126.471 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[65000] Time spent = 657.14 s
65000: eval/seed           : 650
65000: other/elapsed_time  : 515.36
65000: other/episode       : 419
65000: other/replay        : 439
65000: other/speed         : 9.70
65000: other/step          : 65000
65000: other/train_step    : 32499
65000: score/num_success   : 199
65000: score/score         : 0.92
65000: actor/anorm_bc      [ 5000]: avg:   0.6733, min:   0.0188[4708], max:   1.4866[1846]
65000: actor/anorm_rl      [ 5000]: avg:   1.2085, min:   0.2016[2551], max:   2.0277[1148]
65000: actor/bc_eval       [ 4503]: avg:   0.2771, min:   0.0000[   1], max:   4.0000[ 454]
65000: actor/bc_train      [ 5000]: avg:   0.3622, min:   0.0000[   7], max:   1.0000[   1]
65000: actor/bootstrap_bc  [ 2500]: avg:   0.2005, min:   0.1133[ 620], max:   0.3008[1923]
65000: data/batch_R        [ 2500]: avg:   0.0084, min:   0.0000[   1], max:   0.0311[1449]
65000: data/discount       [ 2500]: avg:   0.9515, min:   0.9097[2417], max:   0.9703[  29]
65000: data/episode_len    [   40]: avg: 127.0500, min:  66.0000[  13], max: 200.0000[   1]
65000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  25], max:   0.1000[   2]
65000: score/train_score   [   40]: avg:   0.7000, min:   0.0000[   1], max:   1.0000[   2]
65000: train/actor_loss    [ 2500]: avg:  -0.3418, min:  -0.3991[2453], max:  -0.2815[1176]
65000: train/critic_loss   [ 2500]: avg:   0.0014, min:   0.0006[ 218], max:   0.0071[1522]
65000: train/critic_qt     [ 2500]: avg:   0.3368, min:   0.2778[1176], max:   0.3968[2371]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.9 |  42.6 |
| act      |  5000 |           7.3 |   5.6 |
| env step |  5000 |          26.8 |  20.4 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    40 |        1616.2 |   9.8 |
| eval     |     1 |      141440   |  21.5 |
| total(s) |     1 |         656.6 | 100   |
total time: 2:21:10
Mem info: used: 7.811 GB, avail: 126.424 GB, total: 156.060 GB
[70000] Time spent = 643.38 s
70000: eval/seed           : 700
70000: other/elapsed_time  : 535.50
70000: other/episode       : 471
70000: other/replay        : 491
70000: other/speed         : 9.34
70000: other/step          : 70000
70000: other/train_step    : 34999
70000: score/num_success   : 244
70000: score/score         : 0.84
70000: actor/anorm_bc      [ 5000]: avg:   0.7313, min:   0.0170[3201], max:   1.4897[3976]
70000: actor/anorm_rl      [ 5000]: avg:   1.2235, min:   0.1295[4412], max:   2.4197[4637]
70000: actor/bc_eval       [ 4758]: avg:   0.3016, min:   0.0000[   1], max:   4.0000[ 576]
70000: actor/bc_train      [ 5000]: avg:   0.2934, min:   0.0000[   1], max:   1.0000[   6]
70000: actor/bootstrap_bc  [ 2500]: avg:   0.1982, min:   0.1250[ 140], max:   0.3086[1250]
70000: data/batch_R        [ 2500]: avg:   0.0094, min:   0.0000[   2], max:   0.0349[2160]
70000: data/discount       [ 2500]: avg:   0.9514, min:   0.9172[ 276], max:   0.9703[  15]
70000: data/episode_len    [   52]: avg:  96.1731, min:  58.0000[  38], max: 200.0000[   6]
70000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  54], max:   0.1000[   2]
70000: score/train_score   [   52]: avg:   0.8654, min:   0.0000[   6], max:   1.0000[   1]
70000: train/actor_loss    [ 2500]: avg:  -0.3638, min:  -0.4212[2341], max:  -0.3042[ 366]
70000: train/critic_loss   [ 2500]: avg:   0.0015, min:   0.0006[ 918], max:   0.0054[1128]
70000: train/critic_qt     [ 2500]: avg:   0.3583, min:   0.3004[  95], max:   0.4137[1857]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  43.5 |
| act      |  5000 |           7.3 |   5.7 |
| env step |  5000 |          27   |  21   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    52 |        1605.9 |  13   |
| eval     |     1 |      107711   |  16.8 |
| total(s) |     1 |         643   | 100   |
total time: 2:31:53
Mem info: used: 7.811 GB, avail: 126.400 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[75000] Time spent = 649.93 s
75000: eval/seed           : 750
75000: other/elapsed_time  : 542.97
75000: other/episode       : 527
75000: other/replay        : 547
75000: other/speed         : 9.21
75000: other/step          : 75000
75000: other/train_step    : 37499
75000: score/num_success   : 296
75000: score/score         : 0.92
75000: actor/anorm_bc      [ 5000]: avg:   0.7366, min:   0.0227[3721], max:   1.4551[1311]
75000: actor/anorm_rl      [ 5000]: avg:   1.2354, min:   0.1004[4222], max:   2.2884[2754]
75000: actor/bc_eval       [ 4134]: avg:   0.2700, min:   0.0000[   1], max:   5.0000[3172]
75000: actor/bc_train      [ 5000]: avg:   0.3134, min:   0.0000[   1], max:   1.0000[  15]
75000: actor/bootstrap_bc  [ 2500]: avg:   0.1913, min:   0.1094[1916], max:   0.3008[ 153]
75000: data/batch_R        [ 2500]: avg:   0.0105, min:   0.0000[  19], max:   0.0348[1435]
75000: data/discount       [ 2500]: avg:   0.9502, min:   0.9134[ 426], max:   0.9703[ 221]
75000: data/episode_len    [   56]: avg:  89.0536, min:  51.0000[  39], max: 200.0000[   2]
75000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  54], max:   0.1000[   2]
75000: score/train_score   [   56]: avg:   0.9286, min:   0.0000[   2], max:   1.0000[   1]
75000: train/actor_loss    [ 2500]: avg:  -0.3878, min:  -0.4518[1745], max:  -0.3281[ 870]
75000: train/critic_loss   [ 2500]: avg:   0.0013, min:   0.0006[2331], max:   0.0055[1953]
75000: train/critic_qt     [ 2500]: avg:   0.3819, min:   0.3215[ 870], max:   0.4389[2256]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  43   |
| act      |  5000 |           7.5 |   5.8 |
| env step |  5000 |          27.2 |  21   |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    56 |        1593.1 |  13.7 |
| eval     |     1 |      106639   |  16.4 |
| total(s) |     1 |         649.4 | 100   |
total time: 2:42:43
Mem info: used: 7.811 GB, avail: 126.371 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[80000] Time spent = 640.61 s
80000: eval/seed           : 800
80000: other/elapsed_time  : 529.57
80000: other/episode       : 574
80000: other/replay        : 594
80000: other/speed         : 9.44
80000: other/step          : 80000
80000: other/train_step    : 39999
80000: score/num_success   : 334
80000: score/score         : 0.92
80000: actor/anorm_bc      [ 5000]: avg:   0.6914, min:   0.0110[3205], max:   1.4585[4792]
80000: actor/anorm_rl      [ 5000]: avg:   1.1749, min:   0.1695[2021], max:   2.0634[1580]
80000: actor/bc_eval       [ 4413]: avg:   0.1996, min:   0.0000[   1], max:   4.0000[2397]
80000: actor/bc_train      [ 5000]: avg:   0.3022, min:   0.0000[   3], max:   1.0000[   1]
80000: actor/bootstrap_bc  [ 2500]: avg:   0.1891, min:   0.1094[  63], max:   0.2852[ 122]
80000: data/batch_R        [ 2500]: avg:   0.0116, min:   0.0000[  35], max:   0.0427[1056]
80000: data/discount       [ 2500]: avg:   0.9495, min:   0.9097[1056], max:   0.9703[ 407]
80000: data/episode_len    [   47]: avg: 106.6809, min:  58.0000[  28], max: 200.0000[   1]
80000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  15], max:   0.1000[   2]
80000: score/train_score   [   47]: avg:   0.8085, min:   0.0000[   1], max:   1.0000[   2]
80000: train/actor_loss    [ 2500]: avg:  -0.4114, min:  -0.4679[1598], max:  -0.3622[ 499]
80000: train/critic_loss   [ 2500]: avg:   0.0013, min:   0.0006[1521], max:   0.0071[2385]
80000: train/critic_qt     [ 2500]: avg:   0.4055, min:   0.3513[ 499], max:   0.4625[1598]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  43.7 |
| act      |  5000 |           7.5 |   5.8 |
| env step |  5000 |          27.3 |  21.3 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    47 |        1606.6 |  11.8 |
| eval     |     1 |      110723   |  17.3 |
| total(s) |     1 |         640.1 | 100   |
total time: 2:53:24
Mem info: used: 7.811 GB, avail: 126.334 GB, total: 156.060 GB
[85000] Time spent = 661.67 s
85000: eval/seed           : 850
85000: other/elapsed_time  : 543.81
85000: other/episode       : 631
85000: other/replay        : 651
85000: other/speed         : 9.19
85000: other/step          : 85000
85000: other/train_step    : 42499
85000: score/num_success   : 386
85000: score/score         : 0.82
85000: actor/anorm_bc      [ 5000]: avg:   0.7599, min:   0.0209[2187], max:   1.4705[2861]
85000: actor/anorm_rl      [ 5000]: avg:   1.2199, min:   0.1865[3771], max:   1.9797[3467]
85000: actor/bc_eval       [ 4851]: avg:   0.2068, min:   0.0000[   1], max:   3.0000[ 532]
85000: actor/bc_train      [ 5000]: avg:   0.2392, min:   0.0000[   1], max:   1.0000[  14]
85000: actor/bootstrap_bc  [ 2500]: avg:   0.1928, min:   0.1016[ 368], max:   0.2773[1036]
85000: data/batch_R        [ 2500]: avg:   0.0127, min:   0.0000[  36], max:   0.0464[ 136]
85000: data/discount       [ 2500]: avg:   0.9491, min:   0.9097[ 598], max:   0.9703[ 118]
85000: data/episode_len    [   57]: avg:  86.8070, min:  54.0000[  38], max: 200.0000[  10]
85000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  15], max:   0.1000[   2]
85000: score/train_score   [   57]: avg:   0.9123, min:   0.0000[  10], max:   1.0000[   1]
85000: train/actor_loss    [ 2500]: avg:  -0.4243, min:  -0.4746[2075], max:  -0.3664[ 555]
85000: train/critic_loss   [ 2500]: avg:   0.0013, min:   0.0005[1886], max:   0.0055[2418]
85000: train/critic_qt     [ 2500]: avg:   0.4187, min:   0.3677[ 555], max:   0.4725[ 938]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         112   |  42.3 |
| act      |  5000 |           7.4 |   5.6 |
| env step |  5000 |          27   |  20.4 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    57 |        1596.3 |  13.8 |
| eval     |     1 |      117681   |  17.8 |
| total(s) |     1 |         661.3 | 100   |
total time: 3:04:25
Mem info: used: 7.811 GB, avail: 126.303 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[90000] Time spent = 633.09 s
90000: eval/seed           : 900
90000: other/elapsed_time  : 539.02
90000: other/episode       : 684
90000: other/replay        : 704
90000: other/speed         : 9.28
90000: other/step          : 90000
90000: other/train_step    : 44999
90000: score/num_success   : 432
90000: score/score         : 0.96
90000: actor/anorm_bc      [ 5000]: avg:   0.7135, min:   0.0295[ 624], max:   1.5198[2625]
90000: actor/anorm_rl      [ 5000]: avg:   1.2009, min:   0.1941[4871], max:   1.8375[2632]
90000: actor/bc_eval       [ 3826]: avg:   0.2083, min:   0.0000[   1], max:   4.0000[ 242]
90000: actor/bc_train      [ 5000]: avg:   0.2624, min:   0.0000[   3], max:   1.0000[   1]
90000: actor/bootstrap_bc  [ 2500]: avg:   0.2001, min:   0.1211[ 982], max:   0.3164[1417]
90000: data/batch_R        [ 2500]: avg:   0.0134, min:   0.0000[   3], max:   0.0388[ 981]
90000: data/discount       [ 2500]: avg:   0.9484, min:   0.9172[ 653], max:   0.9703[ 125]
90000: data/episode_len    [   53]: avg:  92.3962, min:  53.0000[  33], max: 200.0000[   1]
90000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  15], max:   0.1000[   9]
90000: score/train_score   [   53]: avg:   0.8679, min:   0.0000[   1], max:   1.0000[   2]
90000: train/actor_loss    [ 2500]: avg:  -0.4277, min:  -0.4809[1899], max:  -0.3726[2481]
90000: train/critic_loss   [ 2500]: avg:   0.0012, min:   0.0005[1616], max:   0.0062[2347]
90000: train/critic_qt     [ 2500]: avg:   0.4230, min:   0.3699[2240], max:   0.4787[1899]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.7 |  44.1 |
| act      |  5000 |           7.5 |   5.9 |
| env step |  5000 |          27.2 |  21.5 |
| add      |  5000 |           0.2 |   0.1 |
| reset    |    53 |        1604   |  13.4 |
| eval     |     1 |       93749.7 |  14.8 |
| total(s) |     1 |         632.6 | 100   |
total time: 3:14:59
Mem info: used: 7.811 GB, avail: 126.254 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[95000] Time spent = 657.71 s
95000: eval/seed           : 950
95000: other/elapsed_time  : 554.97
95000: other/episode       : 748
95000: other/replay        : 768
95000: other/speed         : 9.01
95000: other/step          : 95000
95000: other/train_step    : 47499
95000: score/num_success   : 492
95000: score/score         : 0.96
95000: actor/anorm_bc      [ 5000]: avg:   0.8206, min:   0.0163[ 538], max:   1.5664[2810]
95000: actor/anorm_rl      [ 5000]: avg:   1.2607, min:   0.1866[1702], max:   2.0645[3616]
95000: actor/bc_eval       [ 3706]: avg:   0.2121, min:   0.0000[   1], max:   3.0000[ 857]
95000: actor/bc_train      [ 5000]: avg:   0.2752, min:   0.0000[   1], max:   1.0000[  15]
95000: actor/bootstrap_bc  [ 2500]: avg:   0.2053, min:   0.1133[ 278], max:   0.3086[1331]
95000: data/batch_R        [ 2500]: avg:   0.0145, min:   0.0000[  26], max:   0.0466[2322]
95000: data/discount       [ 2500]: avg:   0.9476, min:   0.9059[2383], max:   0.9703[  46]
95000: data/episode_len    [   64]: avg:  80.5469, min:  51.0000[  35], max: 200.0000[   1]
95000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  34], max:   0.1000[   1]
95000: score/train_score   [   64]: avg:   0.9375, min:   0.0000[   1], max:   1.0000[   2]
95000: train/actor_loss    [ 2500]: avg:  -0.4285, min:  -0.4809[1743], max:  -0.3787[2132]
95000: train/critic_loss   [ 2500]: avg:   0.0012, min:   0.0005[2419], max:   0.0101[ 523]
95000: train/critic_qt     [ 2500]: avg:   0.4240, min:   0.3763[2132], max:   0.4790[1397]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.9 |  42.6 |
| act      |  5000 |           7.4 |   5.6 |
| env step |  5000 |          26.9 |  20.5 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    64 |        1601.6 |  15.6 |
| eval     |     1 |      102424   |  15.6 |
| total(s) |     1 |         657.2 | 100   |
total time: 3:25:56
Mem info: used: 7.819 GB, avail: 126.219 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[100000] Time spent = 638.35 s
100000: eval/seed           : 1000
100000: other/elapsed_time  : 544.29
100000: other/episode       : 808
100000: other/replay        : 828
100000: other/speed         : 9.19
100000: other/step          : 100000
100000: other/train_step    : 49999
100000: score/num_success   : 548
100000: score/score         : 0.98
100000: actor/anorm_bc      [ 5000]: avg:   0.8038, min:   0.0195[3660], max:   1.4479[ 648]
100000: actor/anorm_rl      [ 5000]: avg:   1.2800, min:   0.2562[3313], max:   2.1678[3798]
100000: actor/bc_eval       [ 3460]: avg:   0.1532, min:   0.0000[   1], max:   3.0000[ 452]
100000: actor/bc_train      [ 5000]: avg:   0.2356, min:   0.0000[   1], max:   1.0000[  10]
100000: actor/bootstrap_bc  [ 2500]: avg:   0.1976, min:   0.1172[1928], max:   0.2969[ 940]
100000: data/batch_R        [ 2500]: avg:   0.0153, min:   0.0000[  32], max:   0.0501[1170]
100000: data/discount       [ 2500]: avg:   0.9472, min:   0.9059[1170], max:   0.9703[1275]
100000: data/episode_len    [   60]: avg:  83.3333, min:  52.0000[  13], max: 200.0000[  36]
100000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  34], max:   0.1000[   1]
100000: score/train_score   [   60]: avg:   0.9333, min:   0.0000[  36], max:   1.0000[   1]
100000: train/actor_loss    [ 2500]: avg:  -0.4434, min:  -0.5110[2373], max:  -0.3856[ 415]
100000: train/critic_loss   [ 2500]: avg:   0.0011, min:   0.0005[1194], max:   0.0059[1477]
100000: train/critic_qt     [ 2500]: avg:   0.4383, min:   0.3852[ 415], max:   0.5118[2373]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.5 |  43.7 |
| act      |  5000 |           7.2 |   5.6 |
| env step |  5000 |          26.7 |  20.9 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    60 |        1583.3 |  14.9 |
| eval     |     1 |       93734.4 |  14.7 |
| total(s) |     1 |         637.8 | 100   |
total time: 3:36:35
Mem info: used: 7.819 GB, avail: 126.183 GB, total: 156.060 GB
[105000] Time spent = 632.13 s
105000: eval/seed           : 1050
105000: other/elapsed_time  : 539.54
105000: other/episode       : 863
105000: other/replay        : 883
105000: other/speed         : 9.27
105000: other/step          : 105000
105000: other/train_step    : 52499
105000: score/num_success   : 595
105000: score/score         : 0.94
105000: actor/anorm_bc      [ 5000]: avg:   0.7419, min:   0.0217[ 485], max:   1.5323[4857]
105000: actor/anorm_rl      [ 5000]: avg:   1.3043, min:   0.2463[ 151], max:   2.1669[1005]
105000: actor/bc_eval       [ 3680]: avg:   0.1628, min:   0.0000[   1], max:   4.0000[2629]
105000: actor/bc_train      [ 5000]: avg:   0.2794, min:   0.0000[   1], max:   1.0000[  14]
105000: actor/bootstrap_bc  [ 2500]: avg:   0.2046, min:   0.1133[ 344], max:   0.2852[ 530]
105000: data/batch_R        [ 2500]: avg:   0.0160, min:   0.0000[  41], max:   0.0466[ 269]
105000: data/discount       [ 2500]: avg:   0.9465, min:   0.9134[1687], max:   0.9703[ 885]
105000: data/episode_len    [   55]: avg:  90.6727, min:  49.0000[   1], max: 200.0000[   2]
105000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  53], max:   0.1000[   1]
105000: score/train_score   [   55]: avg:   0.8545, min:   0.0000[   2], max:   1.0000[   1]
105000: train/actor_loss    [ 2500]: avg:  -0.4475, min:  -0.5107[2496], max:  -0.3895[ 795]
105000: train/critic_loss   [ 2500]: avg:   0.0011, min:   0.0004[ 410], max:   0.0091[ 255]
105000: train/critic_qt     [ 2500]: avg:   0.4433, min:   0.3849[ 795], max:   0.5039[2307]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  44.2 |
| act      |  5000 |           7.4 |   5.8 |
| env step |  5000 |          27   |  21.4 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    55 |        1592   |  13.9 |
| eval     |     1 |       92413.7 |  14.6 |
| total(s) |     1 |         631.8 | 100   |
total time: 3:47:07
Mem info: used: 7.819 GB, avail: 126.149 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[110000] Time spent = 664.59 s
110000: eval/seed           : 1100
110000: other/elapsed_time  : 564.61
110000: other/episode       : 929
110000: other/replay        : 949
110000: other/speed         : 8.86
110000: other/step          : 110000
110000: other/train_step    : 54999
110000: score/num_success   : 659
110000: score/score         : 0.98
110000: actor/anorm_bc      [ 5000]: avg:   0.8080, min:   0.0261[ 294], max:   1.4780[2437]
110000: actor/anorm_rl      [ 5000]: avg:   1.3054, min:   0.3451[2602], max:   2.0258[3510]
110000: actor/bc_eval       [ 3518]: avg:   0.1299, min:   0.0000[   1], max:   3.0000[1925]
110000: actor/bc_train      [ 5000]: avg:   0.2094, min:   0.0000[   1], max:   1.0000[   3]
110000: actor/bootstrap_bc  [ 2500]: avg:   0.2084, min:   0.1172[2426], max:   0.3164[  79]
110000: data/batch_R        [ 2500]: avg:   0.0171, min:   0.0000[ 309], max:   0.0503[1624]
110000: data/discount       [ 2500]: avg:   0.9460, min:   0.9097[1665], max:   0.9703[2242]
110000: data/episode_len    [   66]: avg:  75.4697, min:  48.0000[  39], max: 200.0000[  40]
110000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  14], max:   0.1000[   1]
110000: score/train_score   [   66]: avg:   0.9697, min:   0.0000[  40], max:   1.0000[   1]
110000: train/actor_loss    [ 2500]: avg:  -0.4496, min:  -0.5056[ 775], max:  -0.3953[1403]
110000: train/critic_loss   [ 2500]: avg:   0.0011, min:   0.0004[2276], max:   0.0072[ 856]
110000: train/critic_qt     [ 2500]: avg:   0.4456, min:   0.3901[1403], max:   0.5036[ 775]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.4 |  41.9 |
| act      |  5000 |           7.9 |   5.9 |
| env step |  5000 |          27.8 |  20.9 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    66 |        1615.4 |  16.1 |
| eval     |     1 |       99643.6 |  15   |
| total(s) |     1 |         664.1 | 100   |
total time: 3:58:11
Mem info: used: 7.819 GB, avail: 126.065 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[115000] Time spent = 659.92 s
115000: eval/seed           : 1150
115000: other/elapsed_time  : 548.56
115000: other/episode       : 994
115000: other/replay        : 1000
115000: other/speed         : 9.11
115000: other/step          : 115000
115000: other/train_step    : 57499
115000: score/num_success   : 720
115000: score/score         : 0.98
115000: actor/anorm_bc      [ 5000]: avg:   0.7993, min:   0.0253[2292], max:   1.4659[4187]
115000: actor/anorm_rl      [ 5000]: avg:   1.2618, min:   0.1012[3441], max:   2.2068[3381]
115000: actor/bc_eval       [ 3389]: avg:   0.1765, min:   0.0000[   1], max:   5.0000[1123]
115000: actor/bc_train      [ 5000]: avg:   0.2556, min:   0.0000[   3], max:   1.0000[   1]
115000: actor/bootstrap_bc  [ 2500]: avg:   0.2090, min:   0.1328[ 401], max:   0.3047[1528]
115000: data/batch_R        [ 2500]: avg:   0.0176, min:   0.0000[  81], max:   0.0504[ 881]
115000: data/discount       [ 2500]: avg:   0.9457, min:   0.9097[ 302], max:   0.9703[ 146]
115000: data/episode_len    [   65]: avg:  77.0000, min:  51.0000[  32], max: 200.0000[   7]
115000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  14], max:   0.1000[   1]
115000: score/train_score   [   65]: avg:   0.9385, min:   0.0000[   7], max:   1.0000[   1]
115000: train/actor_loss    [ 2500]: avg:  -0.4556, min:  -0.5165[ 660], max:  -0.3940[ 419]
115000: train/critic_loss   [ 2500]: avg:   0.0011, min:   0.0004[1466], max:   0.0073[1687]
115000: train/critic_qt     [ 2500]: avg:   0.4518, min:   0.3889[ 542], max:   0.5072[ 660]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  42.3 |
| act      |  5000 |           7.1 |   5.4 |
| env step |  5000 |          26.4 |  20   |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    65 |        1555.8 |  15.3 |
| eval     |     1 |      111066   |  16.8 |
| total(s) |     1 |         659.4 | 100   |
total time: 4:09:11
Mem info: used: 7.819 GB, avail: 126.362 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[120000] Time spent = 640.77 s
120000: eval/seed           : 1200
120000: other/elapsed_time  : 555.82
120000: other/episode       : 1061
120000: other/replay        : 1000
120000: other/speed         : 9.00
120000: other/step          : 120000
120000: other/train_step    : 59999
120000: score/num_success   : 785
120000: score/score         : 1.00
120000: actor/anorm_bc      [ 5000]: avg:   0.8553, min:   0.0194[ 863], max:   1.4497[4702]
120000: actor/anorm_rl      [ 5000]: avg:   1.3189, min:   0.2890[1567], max:   2.2252[ 237]
120000: actor/bc_eval       [ 3264]: avg:   0.0947, min:   0.0000[   1], max:   3.0000[2792]
120000: actor/bc_train      [ 5000]: avg:   0.2370, min:   0.0000[   2], max:   1.0000[   1]
120000: actor/bootstrap_bc  [ 2500]: avg:   0.2100, min:   0.1133[1733], max:   0.2969[ 173]
120000: data/batch_R        [ 2500]: avg:   0.0193, min:   0.0000[ 144], max:   0.0503[1965]
120000: data/discount       [ 2500]: avg:   0.9445, min:   0.9059[ 156], max:   0.9703[1053]
120000: data/episode_len    [   67]: avg:  74.7463, min:  50.0000[   8], max: 200.0000[   3]
120000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  14], max:   0.1000[   1]
120000: score/train_score   [   67]: avg:   0.9701, min:   0.0000[   3], max:   1.0000[   1]
120000: train/actor_loss    [ 2500]: avg:  -0.4780, min:  -0.5500[2218], max:  -0.4105[ 920]
120000: train/critic_loss   [ 2500]: avg:   0.0011, min:   0.0004[ 473], max:   0.0067[ 859]
120000: train/critic_qt     [ 2500]: avg:   0.4744, min:   0.4060[ 318], max:   0.5489[2218]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.5 |  43.5 |
| act      |  5000 |           7.4 |   5.8 |
| env step |  5000 |          26.7 |  20.8 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    67 |        1574.4 |  16.5 |
| eval     |     1 |       84624.2 |  13.2 |
| total(s) |     1 |         640.3 | 100   |
total time: 4:19:52
Mem info: used: 7.819 GB, avail: 126.338 GB, total: 156.060 GB
[125000] Time spent = 671.76 s
125000: eval/seed           : 1250
125000: other/elapsed_time  : 548.76
125000: other/episode       : 1124
125000: other/replay        : 1000
125000: other/speed         : 9.11
125000: other/step          : 125000
125000: other/train_step    : 62499
125000: score/num_success   : 844
125000: score/score         : 0.96
125000: actor/anorm_bc      [ 5000]: avg:   0.8165, min:   0.0209[1469], max:   1.4978[ 774]
125000: actor/anorm_rl      [ 5000]: avg:   1.3501, min:   0.2847[  97], max:   2.3216[1678]
125000: actor/bc_eval       [ 3499]: avg:   0.1466, min:   0.0000[   1], max:   3.0000[1381]
125000: actor/bc_train      [ 5000]: avg:   0.2206, min:   0.0000[   3], max:   1.0000[   1]
125000: actor/bootstrap_bc  [ 2500]: avg:   0.2057, min:   0.1250[ 434], max:   0.2969[ 180]
125000: data/batch_R        [ 2500]: avg:   0.0226, min:   0.0000[ 312], max:   0.0583[2237]
125000: data/discount       [ 2500]: avg:   0.9424, min:   0.9059[ 627], max:   0.9703[1990]
125000: data/episode_len    [   63]: avg:  79.3968, min:  48.0000[  30], max: 200.0000[  23]
125000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  33], max:   0.1000[   8]
125000: score/train_score   [   63]: avg:   0.9365, min:   0.0000[  23], max:   1.0000[   1]
125000: train/actor_loss    [ 2500]: avg:  -0.5298, min:  -0.5925[2193], max:  -0.4557[  93]
125000: train/critic_loss   [ 2500]: avg:   0.0009, min:   0.0003[2118], max:   0.0059[2033]
125000: train/critic_qt     [ 2500]: avg:   0.5266, min:   0.4487[  93], max:   0.5913[2193]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.9 |  41.7 |
| act      |  5000 |           7.3 |   5.4 |
| env step |  5000 |          26.4 |  19.6 |
| add      |  5000 |           0.2 |   0.1 |
| reset    |    63 |        1584.5 |  14.9 |
| eval     |     1 |      122832   |  18.3 |
| total(s) |     1 |         671.4 | 100   |
total time: 4:31:04
Mem info: used: 7.819 GB, avail: 126.327 GB, total: 156.060 GB
[130000] Time spent = 662.15 s
130000: eval/seed           : 1300
130000: other/elapsed_time  : 565.93
130000: other/episode       : 1197
130000: other/replay        : 1000
130000: other/speed         : 8.84
130000: other/step          : 130000
130000: other/train_step    : 64999
130000: score/num_success   : 916
130000: score/score         : 0.96
130000: actor/anorm_bc      [ 5000]: avg:   0.8549, min:   0.0163[3678], max:   1.4950[ 993]
130000: actor/anorm_rl      [ 5000]: avg:   1.3289, min:   0.3466[ 176], max:   1.9995[3201]
130000: actor/bc_eval       [ 3574]: avg:   0.1704, min:   0.0000[   1], max:   3.0000[ 286]
130000: actor/bc_train      [ 5000]: avg:   0.1792, min:   0.0000[   1], max:   1.0000[  14]
130000: actor/bootstrap_bc  [ 2500]: avg:   0.2076, min:   0.1289[1242], max:   0.3008[ 188]
130000: data/batch_R        [ 2500]: avg:   0.0266, min:   0.0000[ 347], max:   0.0697[2379]
130000: data/discount       [ 2500]: avg:   0.9399, min:   0.9021[1574], max:   0.9703[ 958]
130000: data/episode_len    [   73]: avg:  68.6986, min:  48.0000[  18], max: 200.0000[  49]
130000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   2], max:   0.1000[   8]
130000: score/train_score   [   73]: avg:   0.9863, min:   0.0000[  49], max:   1.0000[   1]
130000: train/actor_loss    [ 2500]: avg:  -0.5653, min:  -0.6236[2283], max:  -0.4982[ 239]
130000: train/critic_loss   [ 2500]: avg:   0.0009, min:   0.0003[ 991], max:   0.0060[1284]
130000: train/critic_qt     [ 2500]: avg:   0.5636, min:   0.4973[ 239], max:   0.6207[2283]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.5 |  42.1 |
| act      |  5000 |           7.4 |   5.6 |
| env step |  5000 |          26.8 |  20.3 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    73 |        1575.1 |  17.4 |
| eval     |     1 |       96050.1 |  14.5 |
| total(s) |     1 |         661.8 | 100   |
total time: 4:42:06
Mem info: used: 7.819 GB, avail: 126.288 GB, total: 156.060 GB
[135000] Time spent = 665.06 s
135000: eval/seed           : 1350
135000: other/elapsed_time  : 559.18
135000: other/episode       : 1267
135000: other/replay        : 1000
135000: other/speed         : 8.94
135000: other/step          : 135000
135000: other/train_step    : 67499
135000: score/num_success   : 983
135000: score/score         : 0.92
135000: actor/anorm_bc      [ 5000]: avg:   0.8217, min:   0.0249[1727], max:   1.5594[2340]
135000: actor/anorm_rl      [ 5000]: avg:   1.3290, min:   0.3013[4879], max:   2.2768[ 195]
135000: actor/bc_eval       [ 3895]: avg:   0.2213, min:   0.0000[   1], max:   4.0000[3451]
135000: actor/bc_train      [ 5000]: avg:   0.1850, min:   0.0000[   2], max:   1.0000[   1]
135000: actor/bootstrap_bc  [ 2500]: avg:   0.2136, min:   0.1328[1014], max:   0.3008[2158]
135000: data/batch_R        [ 2500]: avg:   0.0295, min:   0.0000[1602], max:   0.0659[1360]
135000: data/discount       [ 2500]: avg:   0.9377, min:   0.8983[ 490], max:   0.9703[1602]
135000: data/episode_len    [   70]: avg:  71.6286, min:  48.0000[  16], max: 200.0000[   2]
135000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   2], max:   0.1000[   8]
135000: score/train_score   [   70]: avg:   0.9571, min:   0.0000[   2], max:   1.0000[   1]
135000: train/actor_loss    [ 2500]: avg:  -0.5882, min:  -0.6459[1715], max:  -0.5352[ 438]
135000: train/critic_loss   [ 2500]: avg:   0.0008, min:   0.0003[1375], max:   0.0061[2500]
135000: train/critic_qt     [ 2500]: avg:   0.5871, min:   0.5341[ 438], max:   0.6465[1948]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  42.1 |
| act      |  5000 |           7.2 |   5.5 |
| env step |  5000 |          26.6 |  20   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    70 |        1567.2 |  16.5 |
| eval     |     1 |      105707   |  15.9 |
| total(s) |     1 |         664.7 | 100   |
total time: 4:53:11
Mem info: used: 7.819 GB, avail: 126.254 GB, total: 156.060 GB
[140000] Time spent = 668.91 s
140000: eval/seed           : 1400
140000: other/elapsed_time  : 544.22
140000: other/episode       : 1328
140000: other/replay        : 1000
140000: other/speed         : 9.19
140000: other/step          : 140000
140000: other/train_step    : 69999
140000: score/num_success   : 1039
140000: score/score         : 0.86
140000: actor/anorm_bc      [ 5000]: avg:   0.7780, min:   0.0385[2541], max:   1.4534[4691]
140000: actor/anorm_rl      [ 5000]: avg:   1.3604, min:   0.2808[2529], max:   2.1740[1466]
140000: actor/bc_eval       [ 4126]: avg:   0.2397, min:   0.0000[   1], max:   4.0000[ 352]
140000: actor/bc_train      [ 5000]: avg:   0.2378, min:   0.0000[   2], max:   1.0000[   1]
140000: actor/bootstrap_bc  [ 2500]: avg:   0.2084, min:   0.1250[2448], max:   0.3320[ 587]
140000: data/batch_R        [ 2500]: avg:   0.0305, min:   0.0000[1145], max:   0.0732[1389]
140000: data/discount       [ 2500]: avg:   0.9371, min:   0.8907[1389], max:   0.9703[2141]
140000: data/episode_len    [   61]: avg:  81.3443, min:  50.0000[  17], max: 200.0000[  19]
140000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   2], max:   0.1000[   7]
140000: score/train_score   [   61]: avg:   0.9180, min:   0.0000[  19], max:   1.0000[   1]
140000: train/actor_loss    [ 2500]: avg:  -0.6037, min:  -0.6608[1387], max:  -0.5510[2003]
140000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0003[ 710], max:   0.0085[ 599]
140000: train/critic_qt     [ 2500]: avg:   0.6028, min:   0.5466[2003], max:   0.6549[1387]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  41.7 |
| act      |  5000 |           7.2 |   5.4 |
| env step |  5000 |          26.5 |  19.8 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    61 |        1578.7 |  14.4 |
| eval     |     1 |      124527   |  18.6 |
| total(s) |     1 |         668.6 | 100   |
total time: 5:04:20
Mem info: used: 7.819 GB, avail: 126.210 GB, total: 156.060 GB
[145000] Time spent = 667.87 s
145000: eval/seed           : 1450
145000: other/elapsed_time  : 550.88
145000: other/episode       : 1392
145000: other/replay        : 1000
145000: other/speed         : 9.08
145000: other/step          : 145000
145000: other/train_step    : 72499
145000: score/num_success   : 1096
145000: score/score         : 0.80
145000: actor/anorm_bc      [ 5000]: avg:   0.7374, min:   0.0210[3929], max:   1.4760[2786]
145000: actor/anorm_rl      [ 5000]: avg:   1.3677, min:   0.2737[1047], max:   2.4166[4781]
145000: actor/bc_eval       [ 4619]: avg:   0.2780, min:   0.0000[   1], max:   4.0000[3574]
145000: actor/bc_train      [ 5000]: avg:   0.2352, min:   0.0000[   2], max:   1.0000[   1]
145000: actor/bootstrap_bc  [ 2500]: avg:   0.2027, min:   0.1094[ 545], max:   0.2891[ 404]
145000: data/batch_R        [ 2500]: avg:   0.0316, min:   0.0000[ 360], max:   0.0852[1807]
145000: data/discount       [ 2500]: avg:   0.9363, min:   0.8831[1807], max:   0.9665[ 360]
145000: data/episode_len    [   64]: avg:  78.5469, min:  46.0000[  10], max: 200.0000[   4]
145000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  13], max:   0.1000[   7]
145000: score/train_score   [   64]: avg:   0.8906, min:   0.0000[   4], max:   1.0000[   1]
145000: train/actor_loss    [ 2500]: avg:  -0.6108, min:  -0.6833[1900], max:  -0.5631[ 533]
145000: train/critic_loss   [ 2500]: avg:   0.0008, min:   0.0002[1135], max:   0.0072[1771]
145000: train/critic_qt     [ 2500]: avg:   0.6103, min:   0.5629[ 775], max:   0.6799[1900]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  41.8 |
| act      |  5000 |           7.4 |   5.5 |
| env step |  5000 |          26.6 |  19.9 |
| add      |  5000 |           0.2 |   0.1 |
| reset    |    64 |        1580.7 |  15.2 |
| eval     |     1 |      116822   |  17.5 |
| total(s) |     1 |         667.5 | 100   |
total time: 5:15:28
Mem info: used: 7.819 GB, avail: 126.186 GB, total: 156.060 GB
[150000] Time spent = 652.33 s
150000: eval/seed           : 1500
150000: other/elapsed_time  : 552.35
150000: other/episode       : 1459
150000: other/replay        : 1000
150000: other/speed         : 9.05
150000: other/step          : 150000
150000: other/train_step    : 74999
150000: score/num_success   : 1159
150000: score/score         : 0.94
150000: actor/anorm_bc      [ 5000]: avg:   0.7921, min:   0.0299[ 466], max:   1.5504[ 473]
150000: actor/anorm_rl      [ 5000]: avg:   1.3782, min:   0.1204[3425], max:   2.0968[4794]
150000: actor/bc_eval       [ 3462]: avg:   0.1779, min:   0.0000[   1], max:   3.0000[1118]
150000: actor/bc_train      [ 5000]: avg:   0.2196, min:   0.0000[   1], max:   1.0000[  19]
150000: actor/bootstrap_bc  [ 2500]: avg:   0.1991, min:   0.1055[1611], max:   0.2930[1548]
150000: data/batch_R        [ 2500]: avg:   0.0334, min:   0.0038[ 108], max:   0.0736[2442]
150000: data/discount       [ 2500]: avg:   0.9347, min:   0.8945[1207], max:   0.9665[ 331]
150000: data/episode_len    [   67]: avg:  74.0299, min:  44.0000[  42], max: 200.0000[   1]
150000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   7]
150000: score/train_score   [   67]: avg:   0.9403, min:   0.0000[   1], max:   1.0000[   2]
150000: train/actor_loss    [ 2500]: avg:  -0.6219, min:  -0.6727[1256], max:  -0.5769[ 137]
150000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[1049], max:   0.0056[  97]
150000: train/critic_qt     [ 2500]: avg:   0.6215, min:   0.5763[2155], max:   0.6708[1256]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.7 |  42.8 |
| act      |  5000 |           7.2 |   5.5 |
| env step |  5000 |          26.4 |  20.2 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    67 |        1556.3 |  16   |
| eval     |     1 |       99800.9 |  15.3 |
| total(s) |     1 |         652   | 100   |
total time: 5:26:20
Mem info: used: 7.819 GB, avail: 126.145 GB, total: 156.060 GB
[155000] Time spent = 664.15 s
155000: eval/seed           : 1550
155000: other/elapsed_time  : 557.45
155000: other/episode       : 1529
155000: other/replay        : 1000
155000: other/speed         : 8.97
155000: other/step          : 155000
155000: other/train_step    : 77499
155000: score/num_success   : 1225
155000: score/score         : 0.92
155000: actor/anorm_bc      [ 5000]: avg:   0.8227, min:   0.0265[3090], max:   1.4988[2042]
155000: actor/anorm_rl      [ 5000]: avg:   1.3833, min:   0.2866[3968], max:   2.3281[4043]
155000: actor/bc_eval       [ 3568]: avg:   0.2077, min:   0.0000[   1], max:   3.0000[ 342]
155000: actor/bc_train      [ 5000]: avg:   0.1978, min:   0.0000[   1], max:   1.0000[   3]
155000: actor/bootstrap_bc  [ 2500]: avg:   0.1996, min:   0.1211[2096], max:   0.2930[1573]
155000: data/batch_R        [ 2500]: avg:   0.0338, min:   0.0077[ 986], max:   0.0853[ 576]
155000: data/discount       [ 2500]: avg:   0.9345, min:   0.8831[ 576], max:   0.9627[ 212]
155000: data/episode_len    [   70]: avg:  71.9571, min:  47.0000[  24], max: 200.0000[  16]
155000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   7]
155000: score/train_score   [   70]: avg:   0.9429, min:   0.0000[  16], max:   1.0000[   1]
155000: train/actor_loss    [ 2500]: avg:  -0.6261, min:  -0.6794[1862], max:  -0.5702[ 151]
155000: train/critic_loss   [ 2500]: avg:   0.0006, min:   0.0002[1282], max:   0.0050[2042]
155000: train/critic_qt     [ 2500]: avg:   0.6258, min:   0.5736[ 151], max:   0.6772[1370]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  42   |
| act      |  5000 |           7.2 |   5.4 |
| env step |  5000 |          26.5 |  20   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    70 |        1561.3 |  16.5 |
| eval     |     1 |      106535   |  16   |
| total(s) |     1 |         663.8 | 100   |
total time: 5:37:24
Mem info: used: 7.819 GB, avail: 126.118 GB, total: 156.060 GB
[160000] Time spent = 632.82 s
160000: eval/seed           : 1600
160000: other/elapsed_time  : 533.17
160000: other/episode       : 1584
160000: other/replay        : 1000
160000: other/speed         : 9.38
160000: other/step          : 160000
160000: other/train_step    : 79999
160000: score/num_success   : 1270
160000: score/score         : 0.82
160000: actor/anorm_bc      [ 5000]: avg:   0.6908, min:   0.0224[3717], max:   1.4742[1824]
160000: actor/anorm_rl      [ 5000]: avg:   1.3656, min:   0.1413[2060], max:   2.2138[3933]
160000: actor/bc_eval       [ 4170]: avg:   0.2345, min:   0.0000[   1], max:   4.0000[3237]
160000: actor/bc_train      [ 5000]: avg:   0.2868, min:   0.0000[   1], max:   1.0000[   5]
160000: actor/bootstrap_bc  [ 2500]: avg:   0.1911, min:   0.1094[1695], max:   0.3164[1256]
160000: data/batch_R        [ 2500]: avg:   0.0344, min:   0.0077[2012], max:   0.0733[1488]
160000: data/discount       [ 2500]: avg:   0.9338, min:   0.8945[ 317], max:   0.9627[ 384]
160000: data/episode_len    [   55]: avg:  90.3818, min:  48.0000[   5], max: 200.0000[   1]
160000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   7]
160000: score/train_score   [   55]: avg:   0.8182, min:   0.0000[   1], max:   1.0000[   2]
160000: train/actor_loss    [ 2500]: avg:  -0.6253, min:  -0.6775[2020], max:  -0.5727[2212]
160000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[ 648], max:   0.0060[1239]
160000: train/critic_qt     [ 2500]: avg:   0.6253, min:   0.5746[2212], max:   0.6771[2020]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  44.1 |
| act      |  5000 |           7.2 |   5.7 |
| env step |  5000 |          26.3 |  20.8 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    55 |        1561.2 |  13.6 |
| eval     |     1 |       99448.4 |  15.7 |
| total(s) |     1 |         632.4 | 100   |
total time: 5:47:57
Mem info: used: 7.819 GB, avail: 126.088 GB, total: 156.060 GB
Saved model to exps/rl/run1/model0.pt
[165000] Time spent = 644.74 s
165000: eval/seed           : 1650
165000: other/elapsed_time  : 561.80
165000: other/episode       : 1655
165000: other/replay        : 1000
165000: other/speed         : 8.90
165000: other/step          : 165000
165000: other/train_step    : 82499
165000: score/num_success   : 1337
165000: score/score         : 1.00
165000: actor/anorm_bc      [ 5000]: avg:   0.7847, min:   0.0315[ 675], max:   1.4800[1868]
165000: actor/anorm_rl      [ 5000]: avg:   1.3883, min:   0.2845[4288], max:   2.3350[4434]
165000: actor/bc_eval       [ 3237]: avg:   0.1409, min:   0.0000[   1], max:   4.0000[2746]
165000: actor/bc_train      [ 5000]: avg:   0.2062, min:   0.0000[   1], max:   1.0000[   3]
165000: actor/bootstrap_bc  [ 2500]: avg:   0.2013, min:   0.1094[ 631], max:   0.2969[2225]
165000: data/batch_R        [ 2500]: avg:   0.0351, min:   0.0039[1947], max:   0.0813[ 617]
165000: data/discount       [ 2500]: avg:   0.9331, min:   0.8869[ 617], max:   0.9627[1005]
165000: data/episode_len    [   71]: avg:  71.0282, min:  46.0000[  15], max: 200.0000[  29]
165000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   2]
165000: score/train_score   [   71]: avg:   0.9437, min:   0.0000[  29], max:   1.0000[   1]
165000: train/actor_loss    [ 2500]: avg:  -0.6293, min:  -0.6760[ 435], max:  -0.5769[1255]
165000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[  10], max:   0.0050[1428]
165000: train/critic_qt     [ 2500]: avg:   0.6290, min:   0.5740[1255], max:   0.6739[1612]
saved?: True
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         112   |  43.4 |
| act      |  5000 |           7.4 |   5.7 |
| env step |  5000 |          26.6 |  20.7 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    71 |        1564.3 |  17.2 |
| eval     |     1 |       82634   |  12.8 |
| total(s) |     1 |         644.3 | 100   |
total time: 5:58:42
Mem info: used: 7.819 GB, avail: 126.051 GB, total: 156.060 GB
[170000] Time spent = 667.50 s
170000: eval/seed           : 1700
170000: other/elapsed_time  : 542.89
170000: other/episode       : 1716
170000: other/replay        : 1001
170000: other/speed         : 9.21
170000: other/step          : 170000
170000: other/train_step    : 84999
170000: score/num_success   : 1391
170000: score/score         : 0.86
170000: actor/anorm_bc      [ 5000]: avg:   0.7389, min:   0.0372[2752], max:   1.5416[4902]
170000: actor/anorm_rl      [ 5000]: avg:   1.3921, min:   0.2328[2512], max:   2.3005[1906]
170000: actor/bc_eval       [ 3754]: avg:   0.2003, min:   0.0000[   1], max:   4.0000[1621]
170000: actor/bc_train      [ 5000]: avg:   0.2648, min:   0.0000[   1], max:   1.0000[  21]
170000: actor/bootstrap_bc  [ 2500]: avg:   0.1975, min:   0.1133[ 449], max:   0.3047[1894]
170000: data/batch_R        [ 2500]: avg:   0.0356, min:   0.0077[ 807], max:   0.0774[1462]
170000: data/discount       [ 2500]: avg:   0.9329, min:   0.8869[2293], max:   0.9627[ 807]
170000: data/episode_len    [   61]: avg:  82.2295, min:  45.0000[  31], max: 200.0000[  27]
170000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   2]
170000: score/train_score   [   61]: avg:   0.8852, min:   0.0000[  27], max:   1.0000[   1]
170000: train/actor_loss    [ 2500]: avg:  -0.6361, min:  -0.6876[1055], max:  -0.5838[ 350]
170000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[1623], max:   0.0051[2119]
170000: train/critic_qt     [ 2500]: avg:   0.6358, min:   0.5845[ 350], max:   0.6864[1055]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  41.9 |
| act      |  5000 |           7.2 |   5.4 |
| env step |  5000 |          26.3 |  19.7 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    61 |        1559.6 |  14.3 |
| eval     |     1 |      124444   |  18.7 |
| total(s) |     1 |         667.2 | 100   |
total time: 6:09:49
Mem info: used: 7.819 GB, avail: 126.022 GB, total: 156.060 GB
[175000] Time spent = 643.30 s
175000: eval/seed           : 1750
175000: other/elapsed_time  : 559.65
175000: other/episode       : 1787
175000: other/replay        : 1000
175000: other/speed         : 8.93
175000: other/step          : 175000
175000: other/train_step    : 87499
175000: score/num_success   : 1458
175000: score/score         : 0.98
175000: actor/anorm_bc      [ 5000]: avg:   0.7844, min:   0.0226[  23], max:   1.4728[ 282]
175000: actor/anorm_rl      [ 5000]: avg:   1.4345, min:   0.3936[4448], max:   2.1683[3844]
175000: actor/bc_eval       [ 3080]: avg:   0.1127, min:   0.0000[   1], max:   3.0000[ 719]
175000: actor/bc_train      [ 5000]: avg:   0.2132, min:   0.0000[   1], max:   1.0000[   4]
175000: actor/bootstrap_bc  [ 2500]: avg:   0.1842, min:   0.0977[2141], max:   0.2734[1626]
175000: data/batch_R        [ 2500]: avg:   0.0355, min:   0.0000[ 586], max:   0.0736[1818]
175000: data/discount       [ 2500]: avg:   0.9328, min:   0.8907[2303], max:   0.9703[ 586]
175000: data/episode_len    [   71]: avg:  68.8873, min:  45.0000[  11], max: 200.0000[  24]
175000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   2]
175000: score/train_score   [   71]: avg:   0.9437, min:   0.0000[  24], max:   1.0000[   1]
175000: train/actor_loss    [ 2500]: avg:  -0.6362, min:  -0.6927[1580], max:  -0.5832[1945]
175000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[2469], max:   0.0048[ 890]
175000: train/critic_qt     [ 2500]: avg:   0.6356, min:   0.5836[2468], max:   0.6910[1580]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  43.5 |
| act      |  5000 |           7.3 |   5.7 |
| env step |  5000 |          26.3 |  20.5 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    71 |        1562.7 |  17.3 |
| eval     |     1 |       83491.2 |  13   |
| total(s) |     1 |         643   | 100   |
total time: 6:20:33
Mem info: used: 7.819 GB, avail: 126.289 GB, total: 156.060 GB
[180000] Time spent = 642.08 s
180000: eval/seed           : 1800
180000: other/elapsed_time  : 548.95
180000: other/episode       : 1849
180000: other/replay        : 1000
180000: other/speed         : 9.11
180000: other/step          : 180000
180000: other/train_step    : 89999
180000: score/num_success   : 1512
180000: score/score         : 0.96
180000: actor/anorm_bc      [ 5000]: avg:   0.6898, min:   0.0232[1028], max:   1.5556[1148]
180000: actor/anorm_rl      [ 5000]: avg:   1.4330, min:   0.2132[  46], max:   2.3697[4640]
180000: actor/bc_eval       [ 3142]: avg:   0.1572, min:   0.0000[   1], max:   4.0000[1601]
180000: actor/bc_train      [ 5000]: avg:   0.2444, min:   0.0000[   7], max:   1.0000[   1]
180000: actor/bootstrap_bc  [ 2500]: avg:   0.1801, min:   0.0938[ 472], max:   0.2656[  93]
180000: data/batch_R        [ 2500]: avg:   0.0359, min:   0.0077[2334], max:   0.0889[1013]
180000: data/discount       [ 2500]: avg:   0.9323, min:   0.8831[1013], max:   0.9627[ 797]
180000: data/episode_len    [   62]: avg:  79.1935, min:  40.0000[  53], max: 200.0000[   1]
180000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  20], max:   0.1000[   1]
180000: score/train_score   [   62]: avg:   0.8710, min:   0.0000[   1], max:   1.0000[   2]
180000: train/actor_loss    [ 2500]: avg:  -0.6352, min:  -0.6851[1201], max:  -0.5886[1498]
180000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[ 292], max:   0.0049[2197]
180000: train/critic_qt     [ 2500]: avg:   0.6346, min:   0.5846[2209], max:   0.6872[1201]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.9 |  43.6 |
| act      |  5000 |           7.3 |   5.7 |
| env step |  5000 |          26.7 |  20.8 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    62 |        1581.5 |  15.3 |
| eval     |     1 |       92951.2 |  14.5 |
| total(s) |     1 |         641.7 | 100   |
total time: 6:31:15
Mem info: used: 7.819 GB, avail: 126.272 GB, total: 156.060 GB
[185000] Time spent = 682.38 s
185000: eval/seed           : 1850
185000: other/elapsed_time  : 569.84
185000: other/episode       : 1925
185000: other/replay        : 1000
185000: other/speed         : 8.77
185000: other/step          : 185000
185000: other/train_step    : 92499
185000: score/num_success   : 1585
185000: score/score         : 0.86
185000: actor/anorm_bc      [ 5000]: avg:   0.8088, min:   0.0249[  21], max:   1.4799[3967]
185000: actor/anorm_rl      [ 5000]: avg:   1.4523, min:   0.2989[1978], max:   2.2191[2434]
185000: actor/bc_eval       [ 4118]: avg:   0.2047, min:   0.0000[   1], max:   3.0000[ 447]
185000: actor/bc_train      [ 5000]: avg:   0.1548, min:   0.0000[   1], max:   1.0000[   6]
185000: actor/bootstrap_bc  [ 2500]: avg:   0.1641, min:   0.0898[1903], max:   0.2734[ 943]
185000: data/batch_R        [ 2500]: avg:   0.0368, min:   0.0000[ 165], max:   0.0777[1951]
185000: data/discount       [ 2500]: avg:   0.9314, min:   0.8869[1569], max:   0.9703[ 165]
185000: data/episode_len    [   76]: avg:  68.2368, min:  41.0000[  33], max: 200.0000[   1]
185000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  20], max:   0.1000[   1]
185000: score/train_score   [   76]: avg:   0.9605, min:   0.0000[   1], max:   1.0000[   2]
185000: train/actor_loss    [ 2500]: avg:  -0.6414, min:  -0.6898[1844], max:  -0.5778[ 475]
185000: train/critic_loss   [ 2500]: avg:   0.0007, min:   0.0002[1718], max:   0.0053[1171]
185000: train/critic_qt     [ 2500]: avg:   0.6405, min:   0.5736[ 475], max:   0.6917[1844]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  40.9 |
| act      |  5000 |           7.2 |   5.3 |
| env step |  5000 |          26.8 |  19.6 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    76 |        1582.8 |  17.6 |
| eval     |     1 |      112370   |  16.5 |
| total(s) |     1 |         682   | 100   |
total time: 6:42:37
Mem info: used: 7.819 GB, avail: 126.252 GB, total: 156.060 GB
[190000] Time spent = 658.27 s
190000: eval/seed           : 1900
190000: other/elapsed_time  : 541.47
190000: other/episode       : 1984
190000: other/replay        : 1001
190000: other/speed         : 9.23
190000: other/step          : 190000
190000: other/train_step    : 94999
190000: score/num_success   : 1635
190000: score/score         : 0.82
190000: actor/anorm_bc      [ 5000]: avg:   0.6876, min:   0.0186[3742], max:   1.5734[4562]
190000: actor/anorm_rl      [ 5000]: avg:   1.4412, min:   0.1928[ 370], max:   2.3942[  38]
190000: actor/bc_eval       [ 4132]: avg:   0.2326, min:   0.0000[   2], max:   4.0000[2358]
190000: actor/bc_train      [ 5000]: avg:   0.2888, min:   0.0000[   1], max:   1.0000[  33]
190000: actor/bootstrap_bc  [ 2500]: avg:   0.1806, min:   0.1016[  58], max:   0.2617[1502]
190000: data/batch_R        [ 2500]: avg:   0.0363, min:   0.0039[1544], max:   0.0736[  47]
190000: data/discount       [ 2500]: avg:   0.9318, min:   0.8907[ 250], max:   0.9627[ 723]
190000: data/episode_len    [   59]: avg:  84.9492, min:  44.0000[  50], max: 200.0000[   1]
190000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  19], max:   0.1000[   1]
190000: score/train_score   [   59]: avg:   0.8475, min:   0.0000[   1], max:   1.0000[   2]
190000: train/actor_loss    [ 2500]: avg:  -0.6361, min:  -0.6851[ 298], max:  -0.5845[2029]
190000: train/critic_loss   [ 2500]: avg:   0.0008, min:   0.0003[  28], max:   0.0058[2245]
190000: train/critic_qt     [ 2500]: avg:   0.6357, min:   0.5829[2029], max:   0.6827[ 132]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.6 |  42.4 |
| act      |  5000 |           7.2 |   5.4 |
| env step |  5000 |          26.6 |  20.2 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    59 |        1576.7 |  14.1 |
| eval     |     1 |      116602   |  17.7 |
| total(s) |     1 |         657.9 | 100   |
total time: 6:53:35
Mem info: used: 7.819 GB, avail: 126.229 GB, total: 156.060 GB
[195000] Time spent = 638.48 s
195000: eval/seed           : 1950
195000: other/elapsed_time  : 545.78
195000: other/episode       : 2046
195000: other/replay        : 1000
195000: other/speed         : 9.16
195000: other/step          : 195000
195000: other/train_step    : 97499
195000: score/num_success   : 1689
195000: score/score         : 0.98
195000: actor/anorm_bc      [ 5000]: avg:   0.7239, min:   0.0296[2647], max:   1.4695[4933]
195000: actor/anorm_rl      [ 5000]: avg:   1.4810, min:   0.2376[2905], max:   2.4459[4230]
195000: actor/bc_eval       [ 3044]: avg:   0.1324, min:   0.0000[   1], max:   3.0000[  68]
195000: actor/bc_train      [ 5000]: avg:   0.2572, min:   0.0000[   1], max:   1.0000[   8]
195000: actor/bootstrap_bc  [ 2500]: avg:   0.1801, min:   0.0938[ 283], max:   0.2617[ 518]
195000: data/batch_R        [ 2500]: avg:   0.0361, min:   0.0077[2362], max:   0.0889[ 164]
195000: data/discount       [ 2500]: avg:   0.9319, min:   0.8831[ 164], max:   0.9627[ 133]
195000: data/episode_len    [   62]: avg:  80.0000, min:  39.0000[   6], max: 200.0000[   7]
195000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   1]
195000: score/train_score   [   62]: avg:   0.8710, min:   0.0000[   7], max:   1.0000[   1]
195000: train/actor_loss    [ 2500]: avg:  -0.6306, min:  -0.6753[ 277], max:  -0.5752[ 859]
195000: train/critic_loss   [ 2500]: avg:   0.0009, min:   0.0003[1301], max:   0.0053[1680]
195000: train/critic_qt     [ 2500]: avg:   0.6298, min:   0.5735[ 859], max:   0.6755[ 241]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.7 |  43.8 |
| act      |  5000 |           7.2 |   5.7 |
| env step |  5000 |          26.6 |  20.8 |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    62 |        1559.6 |  15.2 |
| eval     |     1 |       92545.2 |  14.5 |
| total(s) |     1 |         638.1 | 100   |
total time: 7:04:14
Mem info: used: 7.819 GB, avail: 126.195 GB, total: 156.060 GB
[200000] Time spent = 638.27 s
200000: eval/seed           : 2000
200000: other/elapsed_time  : 553.90
200000: other/episode       : 2112
200000: other/replay        : 1000
200000: other/speed         : 9.03
200000: other/step          : 200000
200000: other/train_step    : 99999
200000: score/num_success   : 1747
200000: score/score         : 0.92
200000: actor/anorm_bc      [ 5000]: avg:   0.7590, min:   0.0270[2732], max:   1.4501[1286]
200000: actor/anorm_rl      [ 5000]: avg:   1.4633, min:   0.3493[3973], max:   2.4215[3468]
200000: actor/bc_eval       [ 3185]: avg:   0.1780, min:   0.0000[   2], max:   3.0000[1801]
200000: actor/bc_train      [ 5000]: avg:   0.1934, min:   0.0000[   5], max:   1.0000[   1]
200000: actor/bootstrap_bc  [ 2500]: avg:   0.1622, min:   0.0703[1066], max:   0.2422[1524]
200000: data/batch_R        [ 2500]: avg:   0.0356, min:   0.0000[1153], max:   0.0811[ 146]
200000: data/discount       [ 2500]: avg:   0.9324, min:   0.8831[ 146], max:   0.9627[ 991]
200000: data/episode_len    [   66]: avg:  76.3485, min:  41.0000[  22], max: 200.0000[  27]
200000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   1], max:   0.1000[   1]
200000: score/train_score   [   66]: avg:   0.8788, min:   0.0000[  27], max:   1.0000[   1]
200000: train/actor_loss    [ 2500]: avg:  -0.6513, min:  -0.6981[2260], max:  -0.5944[ 660]
200000: train/critic_loss   [ 2500]: avg:   0.0009, min:   0.0003[2053], max:   0.0062[1749]
200000: train/critic_qt     [ 2500]: avg:   0.6486, min:   0.5944[ 660], max:   0.6989[2106]
saved?: False
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |         111.8 |  43.8 |
| act      |  5000 |           7.3 |   5.7 |
| env step |  5000 |          26.8 |  21   |
| add      |  5000 |           0.1 |   0.1 |
| reset    |    66 |        1564.2 |  16.2 |
| eval     |     1 |       84204.7 |  13.2 |
| total(s) |     1 |         637.9 | 100   |
total time: 7:14:52
Mem info: used: 7.819 GB, avail: 126.156 GB, total: 156.060 GB
