=================config=================
add_bc_loss: 0
batch_size: 256
bc_policy: stickpull
discount: 0.99
env_reward_scale: 1
episode_length: 100
log_per_step: 5000
mix_rl_rate: 1
nstep: 3
num_critic_update: 1
num_eval_episode: 20
num_train_step: 60000
num_warm_up_episode: 50
preload_datapath: release/data/metaworld/StickPull_frame_stack_1_96x96_end_on_success/dataset.hdf5
preload_num_data: 3
pretrain_epoch_len: 10000
pretrain_num_epoch: 0
q_agent:
  act_method: ibrl
  actor:
    dropout: 0.0
    feature_dim: 64
    hidden_dim: 1024
    max_action_norm: -1
    orth: 1
    spatial_emb: 0
  bc_loss_coef: 0.1
  bc_loss_dynamic: 0
  bootstrap_method: ibrl
  critic:
    drop: 0
    feature_dim: 64
    fuse_patch: 1
    hidden_dim: 1024
    norm_weight: 0
    orth: 1
    spatial_emb: 0
  critic_target_tau: 0.01
  device: cuda
  enc_type: drq
  ibrl_eps_greedy: 1
  lr: 0.0001
  resnet:
    downsample: default
    norm_layer: gnn
    shallow: 0
    stem: default
  resnet96:
    shallow: 0
    use_1x1: 0
  soft_ibrl_beta: 10
  state_actor:
    dropout: 0.5
    hidden_dim: 512
    layer_norm: 0
    num_layer: 3
    orth: 0
  state_critic:
    append_action: 0
    dropout: 0.0
    hidden_dim: 512
    layer_norm: 0
    num_k: 2
    num_layer: 3
    num_q: 10
    orth: 0
  stddev_clip: 0.3
  use_prop: 0
  vit:
    depth: 3
    embed_dim: 128
    embed_norm: 0
    embed_style: embed1
    num_heads: 4
    patch_size: 8
    stride: -1
replay_buffer_size: 500
save_dir: experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000
seed: 1
stddev_max: 0.1
stddev_min: 0.1
stddev_step: 500000
update_freq: 2
use_bc: 1
use_wb: 1
========================================
=========config of loaded agent=========
batchsize: 256
dataset:
  action_repeat: 2
  eval_episode_len: 100
  frame_stack: 1
  max_len: -1
  num_data: 3
  obs_stack: 1
  path: data/metaworld/StickPull_frame_stack_1_96x96_end_on_success/dataset.hdf5
  rl_camera: corner2
  use_state: 0
ema: -1
epoch_len: 10000
grad_clip: 5
load_model: none
lr: 0.0001
num_epoch: 2
policy:
  dropout: 0
  feature_dim: 256
  hidden_dim: 1024
  net_type: resnet
  orth_init: 1
  proj_dim: 1024
  resnet:
    downsample: default
    norm_layer: gnn
    shallow: 0
    stem: patch
  use_prop: 0
rl_image_size: 96
robot: Sawyer
save_dir: exps/bc/metaworld/pathStickPull_num_data3_num_epoch2_seed1
seed: 1
task_name: StickPull
use_wb: 1
weight_decay: 0
========================================
norm layer: gnn
===============Env Config===============
{'action_repeat': 2,
 'camera_names': ['corner2'],
 'device': 'cuda',
 'env_name': 'StickPull',
 'episode_length': 100,
 'frame_stack': 1,
 'obs_stack': 1,
 'reward_shaping': False,
 'rl_camera': 'corner2',
 'rl_image_size': 96,
 'robots': 'Sawyer',
 'use_state': 0}
========================================
encoder output dim:  39200
patch output dim:  32
============encoder weights=============
DrQEncoder(
  (transform): Resize(size=84, interpolation=bicubic, max_size=None, antialias=True)
  (convnet): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))
    (1): ReLU()
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (3): ReLU()
    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (5): ReLU()
    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
    (7): ReLU()
  )
)
| Module           |   #Params |      % |
|------------------+-----------+--------|
| convnet.0.weight |       864 |   3.02 |
| convnet.0.bias   |        32 |   0.11 |
| convnet.2.weight |     9,216 |  32.18 |
| convnet.2.bias   |        32 |   0.11 |
| convnet.4.weight |     9,216 |  32.18 |
| convnet.4.bias   |        32 |   0.11 |
| convnet.6.weight |     9,216 |  32.18 |
| convnet.6.bias   |        32 |   0.11 |
| Total            |    28,640 | 100.00 |
=============critic weights=============
Critic(
  (q1): _QNet(
    (obs_proj): Sequential(
      (0): Linear(in_features=39200, out_features=64, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
    )
    (q): Sequential(
      (0): Linear(in_features=68, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Dropout(p=0, inplace=False)
      (6): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (7): ReLU(inplace=True)
      (8): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
  (q2): _QNet(
    (obs_proj): Sequential(
      (0): Linear(in_features=39200, out_features=64, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      (3): ReLU()
    )
    (q): Sequential(
      (0): Linear(in_features=68, out_features=1024, bias=True)
      (1): Dropout(p=0, inplace=False)
      (2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (3): ReLU(inplace=True)
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Dropout(p=0, inplace=False)
      (6): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (7): ReLU(inplace=True)
      (8): Linear(in_features=1024, out_features=1, bias=True)
    )
  )
)
| Module               |   #Params |      % |
|----------------------+-----------+--------|
| q1.obs_proj.0.weight | 2,508,800 |  34.51 |
| q1.obs_proj.0.bias   |        64 |   0.00 |
| q1.obs_proj.2.weight |        64 |   0.00 |
| q1.obs_proj.2.bias   |        64 |   0.00 |
| q1.q.0.weight        |    69,632 |   0.96 |
| q1.q.0.bias          |     1,024 |   0.01 |
| q1.q.2.weight        |     1,024 |   0.01 |
| q1.q.2.bias          |     1,024 |   0.01 |
| q1.q.4.weight        | 1,048,576 |  14.43 |
| q1.q.4.bias          |     1,024 |   0.01 |
| q1.q.6.weight        |     1,024 |   0.01 |
| q1.q.6.bias          |     1,024 |   0.01 |
| q1.q.8.weight        |     1,024 |   0.01 |
| q1.q.8.bias          |         1 |   0.00 |
| q2.obs_proj.0.weight | 2,508,800 |  34.51 |
| q2.obs_proj.0.bias   |        64 |   0.00 |
| q2.obs_proj.2.weight |        64 |   0.00 |
| q2.obs_proj.2.bias   |        64 |   0.00 |
| q2.q.0.weight        |    69,632 |   0.96 |
| q2.q.0.bias          |     1,024 |   0.01 |
| q2.q.2.weight        |     1,024 |   0.01 |
| q2.q.2.bias          |     1,024 |   0.01 |
| q2.q.4.weight        | 1,048,576 |  14.43 |
| q2.q.4.bias          |     1,024 |   0.01 |
| q2.q.6.weight        |     1,024 |   0.01 |
| q2.q.6.bias          |     1,024 |   0.01 |
| q2.q.8.weight        |     1,024 |   0.01 |
| q2.q.8.bias          |         1 |   0.00 |
| Total                | 7,268,738 | 100.00 |
=============actor weights==============
Actor(
  (compress): Sequential(
    (0): Linear(in_features=39200, out_features=64, bias=True)
    (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (2): Dropout(p=0.0, inplace=False)
    (3): ReLU()
  )
  (policy): Sequential(
    (0): Linear(in_features=64, out_features=1024, bias=True)
    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (2): Dropout(p=0.0, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=1024, out_features=1024, bias=True)
    (5): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (6): Dropout(p=0.0, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=1024, out_features=4, bias=True)
    (9): Tanh()
  )
)
| Module            |   #Params |      % |
|-------------------+-----------+--------|
| compress.0.weight | 2,508,800 |  69.05 |
| compress.0.bias   |        64 |   0.00 |
| compress.1.weight |        64 |   0.00 |
| compress.1.bias   |        64 |   0.00 |
| policy.0.weight   |    65,536 |   1.80 |
| policy.0.bias     |     1,024 |   0.03 |
| policy.1.weight   |     1,024 |   0.03 |
| policy.1.bias     |     1,024 |   0.03 |
| policy.4.weight   | 1,048,576 |  28.86 |
| policy.4.bias     |     1,024 |   0.03 |
| policy.5.weight   |     1,024 |   0.03 |
| policy.5.bias     |     1,024 |   0.03 |
| policy.8.weight   |     4,096 |   0.11 |
| policy.8.bias     |         4 |   0.00 |
| Total             | 3,633,348 | 100.00 |
loading first 3 episodes from release/data/metaworld/StickPull_frame_stack_1_96x96_end_on_success/dataset.hdf5
Raw Dataset size (#episode): 5
rewards: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 1.]
rewards: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1.]
rewards: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 1.]
Size of the replay buffer: 3, # success: 3
obs torch.Size([3, 96, 96])
prop torch.Size([4])
Warm up done. #episode: 50
#episode from warmup: 47, #reward: 4.0
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[5000] Time spent = 479.58 s
5000: other/elapsed_time  : 360.90
5000: other/episode       : 50
5000: other/replay        : 100
5000: other/speed         : 13.85
5000: other/step          : 5000
5000: other/train_step    : 2499
5000: score/num_success   : 7
5000: score/score         : 0.05
5000: actor/anorm_bc      [ 5000]: avg:   1.3177, min:   0.2076[2591], max:   1.9984[1204]
5000: actor/anorm_rl      [ 5000]: avg:   1.8364, min:   1.1875[   2], max:   2.0000[  11]
5000: actor/bc_eval       [ 1950]: avg:   0.7641, min:   0.0000[   1], max:   1.0000[   2]
5000: actor/bc_train      [ 5000]: avg:   0.4680, min:   0.0000[   1], max:   1.0000[  18]
5000: actor/bootstrap_bc  [ 2499]: avg:   0.4354, min:   0.0000[  48], max:   0.8945[   2]
5000: data/batch_R        [ 2499]: avg:   0.0030, min:   0.0000[   3], max:   0.0234[ 989]
5000: data/discount       [ 2499]: avg:   0.9397, min:   0.8983[1974], max:   0.9703[1256]
5000: data/episode_len    [   50]: avg: 100.0000, min: 100.0000[   1], max: 100.0000[   1]
5000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  17], max:   0.1000[   2]
5000: score/train_score   [   50]: avg:   0.0000, min:   0.0000[   1], max:   0.0000[   1]
5000: train/actor_loss    [ 2499]: avg:   0.0523, min:  -0.0368[1980], max:   2.2094[   1]
5000: train/critic_loss   [ 2499]: avg:   0.0101, min:   0.0003[1092], max:   4.2901[   2]
5000: train/critic_qt     [ 2499]: avg:  -0.0441, min:  -0.6524[   1], max:   0.0263[1980]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| act      |  5000 |          13.4 |  16.5 |
| env step |  5000 |           8.5 |  10.5 |
| add      |  5000 |           0.2 |   0.2 |
| train    |  2499 |          99.7 |  61.4 |
| reset    |    50 |          26.7 |   0.3 |
| eval     |     1 |       45253.3 |  11.1 |
| total(s) |     1 |         405.9 | 100   |
total time: 0:06:46
Mem info: used: 6.808 GB, avail: 127.681 GB, total: 156.060 GB
saved?: False
[10000] Time spent = 402.21 s
10000: other/elapsed_time  : 356.10
10000: other/episode       : 100
10000: other/replay        : 150
10000: other/speed         : 14.04
10000: other/step          : 10000
10000: other/train_step    : 4999
10000: score/num_success   : 7
10000: score/score         : 0.00
10000: actor/anorm_bc      [ 5000]: avg:   1.2076, min:   0.1178[2098], max:   1.9978[1601]
10000: actor/anorm_rl      [ 5000]: avg:   1.7229, min:   0.7162[3683], max:   2.0000[  17]
10000: actor/bc_eval       [ 2000]: avg:   0.3650, min:   0.0000[   1], max:   1.0000[   2]
10000: actor/bc_train      [ 5000]: avg:   0.4008, min:   0.0000[   1], max:   1.0000[   4]
10000: actor/bootstrap_bc  [ 2500]: avg:   0.3336, min:   0.0586[1333], max:   0.7617[ 299]
10000: data/batch_R        [ 2500]: avg:   0.0018, min:   0.0000[   2], max:   0.0156[1330]
10000: data/discount       [ 2500]: avg:   0.9401, min:   0.9021[ 499], max:   0.9703[2170]
10000: data/episode_len    [   50]: avg: 100.0000, min: 100.0000[   1], max: 100.0000[   1]
10000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[   2]
10000: score/train_score   [   50]: avg:   0.0000, min:   0.0000[   1], max:   0.0000[   1]
10000: train/actor_loss    [ 2500]: avg:  -0.0691, min:  -0.1909[2290], max:   0.0519[  97]
10000: train/critic_loss   [ 2500]: avg:   0.0036, min:   0.0009[ 190], max:   0.0123[  14]
10000: train/critic_qt     [ 2500]: avg:   0.0667, min:  -0.0262[  18], max:   0.1741[2480]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          97.8 |  60.8 |
| act      |  5000 |          13.5 |  16.8 |
| env step |  5000 |           8.4 |  10.4 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    50 |          26.4 |   0.3 |
| eval     |     1 |       45901   |  11.4 |
| total(s) |     1 |         401.8 | 100   |
total time: 0:13:28
Mem info: used: 6.808 GB, avail: 127.697 GB, total: 156.060 GB
saved?: False
[15000] Time spent = 416.18 s
15000: other/elapsed_time  : 363.37
15000: other/episode       : 150
15000: other/replay        : 200
15000: other/speed         : 13.76
15000: other/step          : 15000
15000: other/train_step    : 7499
15000: score/num_success   : 8
15000: score/score         : 0.00
15000: actor/anorm_bc      [ 5000]: avg:   1.2780, min:   0.1394[3862], max:   1.9976[1301]
15000: actor/anorm_rl      [ 5000]: avg:   1.5094, min:   0.2261[ 673], max:   2.0000[ 191]
15000: actor/bc_eval       [ 2000]: avg:   0.1240, min:   0.0000[   4], max:   1.0000[   1]
15000: actor/bc_train      [ 5000]: avg:   0.3046, min:   0.0000[   1], max:   1.0000[   8]
15000: actor/bootstrap_bc  [ 2500]: avg:   0.2024, min:   0.1055[2155], max:   0.3516[1405]
15000: data/batch_R        [ 2500]: avg:   0.0013, min:   0.0000[   2], max:   0.0117[ 548]
15000: data/discount       [ 2500]: avg:   0.9409, min:   0.9021[ 637], max:   0.9665[ 309]
15000: data/episode_len    [   50]: avg:  98.9200, min:  46.0000[  21], max: 100.0000[   1]
15000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[   4]
15000: score/train_score   [   50]: avg:   0.0200, min:   0.0000[   1], max:   1.0000[  21]
15000: train/actor_loss    [ 2500]: avg:  -0.1447, min:  -0.1960[ 658], max:  -0.0900[1440]
15000: train/critic_loss   [ 2500]: avg:   0.0039, min:   0.0012[1316], max:   0.0160[2071]
15000: train/critic_qt     [ 2500]: avg:   0.1406, min:   0.1060[1440], max:   0.1879[ 772]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          98.5 |  59.2 |
| act      |  5000 |          14.1 |  16.9 |
| env step |  5000 |           8.8 |  10.6 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    50 |          30.3 |   0.4 |
| eval     |     1 |       52595.7 |  12.7 |
| total(s) |     1 |         415.7 | 100   |
total time: 0:20:24
Mem info: used: 6.808 GB, avail: 127.203 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[20000] Time spent = 408.42 s
20000: other/elapsed_time  : 366.80
20000: other/episode       : 203
20000: other/replay        : 253
20000: other/speed         : 13.63
20000: other/step          : 20000
20000: other/train_step    : 9999
20000: score/num_success   : 16
20000: score/score         : 0.30
20000: actor/anorm_bc      [ 5000]: avg:   1.3792, min:   0.3859[3409], max:   1.9979[ 347]
20000: actor/anorm_rl      [ 5000]: avg:   1.4576, min:   0.3148[1789], max:   2.0000[ 643]
20000: actor/bc_eval       [ 1727]: avg:   0.1957, min:   0.0000[   1], max:   1.0000[   4]
20000: actor/bc_train      [ 5000]: avg:   0.2106, min:   0.0000[   1], max:   1.0000[   2]
20000: actor/bootstrap_bc  [ 2500]: avg:   0.1657, min:   0.0664[ 366], max:   0.2734[2051]
20000: data/batch_R        [ 2500]: avg:   0.0012, min:   0.0000[   1], max:   0.0117[1975]
20000: data/discount       [ 2500]: avg:   0.9407, min:   0.8945[ 928], max:   0.9703[1743]
20000: data/episode_len    [   53]: avg:  93.6981, min:  48.0000[  49], max: 100.0000[   1]
20000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[   4]
20000: score/train_score   [   53]: avg:   0.1509, min:   0.0000[   1], max:   1.0000[  31]
20000: train/actor_loss    [ 2500]: avg:  -0.1209, min:  -0.1796[ 527], max:  -0.0752[2050]
20000: train/critic_loss   [ 2500]: avg:   0.0025, min:   0.0007[1883], max:   0.0093[   8]
20000: train/critic_qt     [ 2500]: avg:   0.1184, min:   0.0835[1883], max:   0.1647[ 296]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          98.9 |  60.6 |
| act      |  5000 |          14.2 |  17.4 |
| env step |  5000 |           9.2 |  11.3 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    53 |          30.3 |   0.4 |
| eval     |     1 |       41190.4 |  10.1 |
| total(s) |     1 |         407.8 | 100   |
total time: 0:27:13
Mem info: used: 6.808 GB, avail: 127.823 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[25000] Time spent = 397.31 s
25000: other/elapsed_time  : 357.20
25000: other/episode       : 262
25000: other/replay        : 312
25000: other/speed         : 14.00
25000: other/step          : 25000
25000: other/train_step    : 12499
25000: score/num_success   : 40
25000: score/score         : 0.35
25000: actor/anorm_bc      [ 5000]: avg:   1.3024, min:   0.4401[ 712], max:   1.9979[ 113]
25000: actor/anorm_rl      [ 5000]: avg:   1.3474, min:   0.2461[4415], max:   2.0000[2370]
25000: actor/bc_eval       [ 1676]: avg:   0.0955, min:   0.0000[   1], max:   1.0000[  23]
25000: actor/bc_train      [ 5000]: avg:   0.1906, min:   0.0000[   1], max:   1.0000[   2]
25000: actor/bootstrap_bc  [ 2500]: avg:   0.1189, min:   0.0352[1463], max:   0.2500[  60]
25000: data/batch_R        [ 2500]: avg:   0.0031, min:   0.0000[   1], max:   0.0271[2304]
25000: data/discount       [ 2500]: avg:   0.9398, min:   0.8907[1080], max:   0.9665[ 421]
25000: data/episode_len    [   59]: avg:  85.2373, min:  45.0000[  20], max: 100.0000[   1]
25000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   7], max:   0.1000[  11]
25000: score/train_score   [   59]: avg:   0.4068, min:   0.0000[   1], max:   1.0000[   8]
25000: train/actor_loss    [ 2500]: avg:  -0.1445, min:  -0.2290[2415], max:  -0.0725[ 434]
25000: train/critic_loss   [ 2500]: avg:   0.0034, min:   0.0008[  47], max:   0.0136[1215]
25000: train/critic_qt     [ 2500]: avg:   0.1384, min:   0.0813[  15], max:   0.2165[2422]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          97.3 |  61.3 |
| act      |  5000 |          13.6 |  17.2 |
| env step |  5000 |           8.6 |  10.9 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    59 |          27.3 |   0.4 |
| eval     |     1 |       39659.7 |  10   |
| total(s) |     1 |         396.7 | 100   |
total time: 0:33:50
Mem info: used: 6.808 GB, avail: 127.848 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[30000] Time spent = 389.54 s
30000: other/elapsed_time  : 355.96
30000: other/episode       : 324
30000: other/replay        : 374
30000: other/speed         : 14.05
30000: other/step          : 30000
30000: other/train_step    : 14999
30000: score/num_success   : 67
30000: score/score         : 0.60
30000: actor/anorm_bc      [ 5000]: avg:   1.3096, min:   0.2974[3400], max:   1.9980[ 217]
30000: actor/anorm_rl      [ 5000]: avg:   1.4842, min:   0.2982[1197], max:   2.0000[1065]
30000: actor/bc_eval       [ 1389]: avg:   0.1044, min:   0.0000[   1], max:   1.0000[  34]
30000: actor/bc_train      [ 5000]: avg:   0.1940, min:   0.0000[   2], max:   1.0000[   1]
30000: actor/bootstrap_bc  [ 2500]: avg:   0.1186, min:   0.0508[2473], max:   0.2070[ 661]
30000: data/batch_R        [ 2500]: avg:   0.0046, min:   0.0000[   5], max:   0.0310[2388]
30000: data/discount       [ 2500]: avg:   0.9396, min:   0.8945[2140], max:   0.9703[ 402]
30000: data/episode_len    [   62]: avg:  81.3548, min:  43.0000[  54], max: 100.0000[   1]
30000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  26], max:   0.1000[  11]
30000: score/train_score   [   62]: avg:   0.4355, min:   0.0000[   1], max:   1.0000[   2]
30000: train/actor_loss    [ 2500]: avg:  -0.2292, min:  -0.2935[2044], max:  -0.1670[   9]
30000: train/critic_loss   [ 2500]: avg:   0.0044, min:   0.0016[ 749], max:   0.0119[1235]
30000: train/critic_qt     [ 2500]: avg:   0.2182, min:   0.1664[  10], max:   0.2745[1926]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          96.9 |  62.3 |
| act      |  5000 |          13.4 |  17.3 |
| env step |  5000 |           8.8 |  11.3 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    62 |          27.6 |   0.4 |
| eval     |     1 |       33193   |   8.5 |
| total(s) |     1 |         388.9 | 100   |
total time: 0:40:20
Mem info: used: 6.796 GB, avail: 127.905 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[35000] Time spent = 388.98 s
35000: other/elapsed_time  : 356.16
35000: other/episode       : 402
35000: other/replay        : 452
35000: other/speed         : 14.04
35000: other/step          : 35000
35000: other/train_step    : 17499
35000: score/num_success   : 127
35000: score/score         : 0.65
35000: actor/anorm_bc      [ 5000]: avg:   1.3191, min:   0.3066[1961], max:   1.9979[1337]
35000: actor/anorm_rl      [ 5000]: avg:   1.4676, min:   0.1896[4985], max:   2.0000[1543]
35000: actor/bc_eval       [ 1359]: avg:   0.1531, min:   0.0000[   1], max:   1.0000[  27]
35000: actor/bc_train      [ 5000]: avg:   0.1528, min:   0.0000[   2], max:   1.0000[   1]
35000: actor/bootstrap_bc  [ 2500]: avg:   0.1029, min:   0.0430[1042], max:   0.1758[ 360]
35000: data/batch_R        [ 2500]: avg:   0.0076, min:   0.0000[   2], max:   0.0348[2087]
35000: data/discount       [ 2500]: avg:   0.9377, min:   0.8907[1564], max:   0.9665[ 195]
35000: data/episode_len    [   78]: avg:  63.6667, min:  41.0000[  34], max: 100.0000[   3]
35000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  16], max:   0.1000[   3]
35000: score/train_score   [   78]: avg:   0.7692, min:   0.0000[   3], max:   1.0000[   1]
35000: train/actor_loss    [ 2500]: avg:  -0.2729, min:  -0.3673[2476], max:  -0.2065[  12]
35000: train/critic_loss   [ 2500]: avg:   0.0050, min:   0.0022[ 813], max:   0.0151[ 365]
35000: train/critic_qt     [ 2500]: avg:   0.2621, min:   0.2009[  12], max:   0.3546[2476]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          96.6 |  62.2 |
| act      |  5000 |          13.5 |  17.4 |
| env step |  5000 |           8.7 |  11.2 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |    78 |          27.7 |   0.6 |
| eval     |     1 |       32431.2 |   8.4 |
| total(s) |     1 |         388.4 | 100   |
total time: 0:46:49
Mem info: used: 6.796 GB, avail: 127.878 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[40000] Time spent = 382.96 s
40000: other/elapsed_time  : 357.68
40000: other/episode       : 497
40000: other/replay        : 500
40000: other/speed         : 13.98
40000: other/step          : 40000
40000: other/train_step    : 19999
40000: score/num_success   : 215
40000: score/score         : 0.90
40000: actor/anorm_bc      [ 5000]: avg:   1.3333, min:   0.3139[1932], max:   1.9979[1370]
40000: actor/anorm_rl      [ 5000]: avg:   1.4926, min:   0.3203[3263], max:   2.0000[ 675]
40000: actor/bc_eval       [ 1019]: avg:   0.0599, min:   0.0000[   1], max:   1.0000[  48]
40000: actor/bc_train      [ 5000]: avg:   0.1106, min:   0.0000[   1], max:   1.0000[  28]
40000: actor/bootstrap_bc  [ 2500]: avg:   0.0946, min:   0.0352[1475], max:   0.1641[ 209]
40000: data/batch_R        [ 2500]: avg:   0.0122, min:   0.0000[   5], max:   0.0388[1566]
40000: data/discount       [ 2500]: avg:   0.9355, min:   0.8831[ 158], max:   0.9665[   5]
40000: data/episode_len    [   95]: avg:  53.0000, min:  38.0000[  90], max: 100.0000[   1]
40000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  16], max:   0.1000[   3]
40000: score/train_score   [   95]: avg:   0.9263, min:   0.0000[   1], max:   1.0000[   2]
40000: train/actor_loss    [ 2500]: avg:  -0.3456, min:  -0.4372[2462], max:  -0.2425[ 529]
40000: train/critic_loss   [ 2500]: avg:   0.0056, min:   0.0025[ 365], max:   0.0141[ 793]
40000: train/critic_qt     [ 2500]: avg:   0.3322, min:   0.2508[ 529], max:   0.4190[2467]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          96.6 |  63.2 |
| act      |  5000 |          13.5 |  17.6 |
| env step |  5000 |           9   |  11.7 |
| add      |  5000 |           0.2 |   0.3 |
| reset    |    95 |          26.8 |   0.7 |
| eval     |     1 |       24856.7 |   6.5 |
| total(s) |     1 |         382.3 | 100   |
total time: 0:53:12
Mem info: used: 6.796 GB, avail: 127.856 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[45000] Time spent = 382.10 s
45000: other/elapsed_time  : 358.20
45000: other/episode       : 599
45000: other/replay        : 500
45000: other/speed         : 13.96
45000: other/step          : 45000
45000: other/train_step    : 22499
45000: score/num_success   : 312
45000: score/score         : 0.95
45000: actor/anorm_bc      [ 5000]: avg:   1.3210, min:   0.2962[1503], max:   1.9980[2907]
45000: actor/anorm_rl      [ 5000]: avg:   1.5166, min:   0.3798[1651], max:   2.0000[ 671]
45000: actor/bc_eval       [  961]: avg:   0.0364, min:   0.0000[   1], max:   1.0000[   5]
45000: actor/bc_train      [ 5000]: avg:   0.0896, min:   0.0000[   1], max:   1.0000[  27]
45000: actor/bootstrap_bc  [ 2500]: avg:   0.0861, min:   0.0312[ 162], max:   0.1719[1139]
45000: data/batch_R        [ 2500]: avg:   0.0201, min:   0.0000[   7], max:   0.0543[2429]
45000: data/discount       [ 2500]: avg:   0.9318, min:   0.8831[1209], max:   0.9665[ 480]
45000: data/episode_len    [  102]: avg:  49.0392, min:  34.0000[  72], max: 100.0000[   4]
45000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   6], max:   0.1000[   3]
45000: score/train_score   [  102]: avg:   0.9510, min:   0.0000[   4], max:   1.0000[   1]
45000: train/actor_loss    [ 2500]: avg:  -0.4537, min:  -0.5617[2440], max:  -0.3407[ 204]
45000: train/critic_loss   [ 2500]: avg:   0.0051, min:   0.0021[2454], max:   0.0151[1581]
45000: train/critic_qt     [ 2500]: avg:   0.4400, min:   0.3269[ 127], max:   0.5560[2454]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          96.5 |  63.2 |
| act      |  5000 |          13.5 |  17.7 |
| env step |  5000 |           9.1 |  12   |
| add      |  5000 |           0.2 |   0.2 |
| reset    |   102 |          27.3 |   0.7 |
| eval     |     1 |       23488.9 |   6.2 |
| total(s) |     1 |         381.5 | 100   |
total time: 0:59:34
Mem info: used: 6.796 GB, avail: 127.852 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[50000] Time spent = 380.76 s
50000: other/elapsed_time  : 358.07
50000: other/episode       : 708
50000: other/replay        : 501
50000: other/speed         : 13.96
50000: other/step          : 50000
50000: other/train_step    : 24999
50000: score/num_success   : 418
50000: score/score         : 0.95
50000: actor/anorm_bc      [ 5000]: avg:   1.3335, min:   0.2419[1916], max:   1.9979[2144]
50000: actor/anorm_rl      [ 5000]: avg:   1.5649, min:   0.3297[3212], max:   2.0000[ 226]
50000: actor/bc_eval       [  886]: avg:   0.0711, min:   0.0000[   1], max:   1.0000[   2]
50000: actor/bc_train      [ 5000]: avg:   0.0914, min:   0.0000[   1], max:   1.0000[  18]
50000: actor/bootstrap_bc  [ 2500]: avg:   0.0816, min:   0.0234[2138], max:   0.1445[2320]
50000: data/batch_R        [ 2500]: avg:   0.0328, min:   0.0038[ 237], max:   0.0814[2321]
50000: data/discount       [ 2500]: avg:   0.9251, min:   0.8718[1531], max:   0.9589[ 173]
50000: data/episode_len    [  109]: avg:  45.9725, min:  34.0000[ 108], max: 100.0000[  24]
50000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   6], max:   0.1000[   3]
50000: score/train_score   [  109]: avg:   0.9725, min:   0.0000[  24], max:   1.0000[   1]
50000: train/actor_loss    [ 2500]: avg:  -0.5948, min:  -0.6953[2279], max:  -0.4697[ 151]
50000: train/critic_loss   [ 2500]: avg:   0.0048, min:   0.0019[1984], max:   0.0159[1458]
50000: train/critic_qt     [ 2500]: avg:   0.5838, min:   0.4600[ 151], max:   0.6878[2279]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          96.7 |  63.6 |
| act      |  5000 |          13.4 |  17.6 |
| env step |  5000 |           9.1 |  11.9 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |   109 |          28   |   0.8 |
| eval     |     1 |       22229.9 |   5.8 |
| total(s) |     1 |         380.1 | 100   |
total time: 1:05:54
Mem info: used: 6.796 GB, avail: 127.829 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[55000] Time spent = 380.23 s
55000: other/elapsed_time  : 358.34
55000: other/episode       : 816
55000: other/replay        : 500
55000: other/speed         : 13.95
55000: other/step          : 55000
55000: other/train_step    : 27499
55000: score/num_success   : 518
55000: score/score         : 0.95
55000: actor/anorm_bc      [ 5000]: avg:   1.3378, min:   0.4468[2666], max:   1.9979[3693]
55000: actor/anorm_rl      [ 5000]: avg:   1.5921, min:   0.5804[1601], max:   2.0000[ 393]
55000: actor/bc_eval       [  882]: avg:   0.0850, min:   0.0000[   2], max:   1.0000[   1]
55000: actor/bc_train      [ 5000]: avg:   0.1176, min:   0.0000[   1], max:   1.0000[  29]
55000: actor/bootstrap_bc  [ 2500]: avg:   0.0857, min:   0.0312[ 546], max:   0.1602[2373]
55000: data/batch_R        [ 2500]: avg:   0.0462, min:   0.0039[  48], max:   0.0930[1515]
55000: data/discount       [ 2500]: avg:   0.9174, min:   0.8642[ 187], max:   0.9589[ 550]
55000: data/episode_len    [  108]: avg:  46.1944, min:  34.0000[  59], max: 100.0000[  22]
55000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[   6], max:   0.1000[  10]
55000: score/train_score   [  108]: avg:   0.9259, min:   0.0000[  22], max:   1.0000[   1]
55000: train/actor_loss    [ 2500]: avg:  -0.6985, min:  -0.7785[2223], max:  -0.6272[  63]
55000: train/critic_loss   [ 2500]: avg:   0.0039, min:   0.0011[1586], max:   0.0141[ 284]
55000: train/critic_qt     [ 2500]: avg:   0.6920, min:   0.6233[  48], max:   0.7669[2223]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          96.6 |  63.6 |
| act      |  5000 |          13.6 |  17.9 |
| env step |  5000 |           9   |  11.8 |
| add      |  5000 |           0.2 |   0.2 |
| reset    |   108 |          27.2 |   0.8 |
| eval     |     1 |       21466.6 |   5.7 |
| total(s) |     1 |         379.6 | 100   |
total time: 1:12:15
Mem info: used: 6.791 GB, avail: 127.849 GB, total: 156.060 GB
Saved model to experiments/rl/metaworld/ibrl_stickpull_seed1_fullbc_60000/model0.pt
saved?: True
[60000] Time spent = 283.57 s
60000: other/elapsed_time  : 268.98
60000: other/episode       : 919
60000: other/replay        : 500
60000: other/speed         : 18.59
60000: other/step          : 60000
60000: other/train_step    : 29999
60000: score/num_success   : 611
60000: score/score         : 0.95
60000: actor/anorm_bc      [ 5000]: avg:   1.3484, min:   0.3343[4556], max:   1.9979[3193]
60000: actor/anorm_rl      [ 5000]: avg:   1.5807, min:   0.5353[3281], max:   2.0000[  61]
60000: actor/bc_eval       [  815]: avg:   0.1006, min:   0.0000[   1], max:   1.0000[  22]
60000: actor/bc_train      [ 5000]: avg:   0.1176, min:   0.0000[   1], max:   1.0000[  11]
60000: actor/bootstrap_bc  [ 2500]: avg:   0.0889, min:   0.0195[1290], max:   0.1641[ 855]
60000: data/batch_R        [ 2500]: avg:   0.0559, min:   0.0155[ 539], max:   0.1121[ 481]
60000: data/discount       [ 2500]: avg:   0.9113, min:   0.8604[ 481], max:   0.9513[ 350]
60000: data/episode_len    [  103]: avg:  48.4466, min:  34.0000[  22], max: 100.0000[   2]
60000: data/stddev         [ 5000]: avg:   0.1000, min:   0.1000[  35], max:   0.1000[  10]
60000: score/train_score   [  103]: avg:   0.9029, min:   0.0000[   2], max:   1.0000[   1]
60000: train/actor_loss    [ 2500]: avg:  -0.7416, min:  -0.7817[2288], max:  -0.6983[ 776]
60000: train/critic_loss   [ 2500]: avg:   0.0035, min:   0.0008[ 133], max:   0.0153[1957]
60000: train/critic_qt     [ 2500]: avg:   0.7394, min:   0.6959[2145], max:   0.7838[1831]
Timer Info:
| name     |   num |   t/call (ms) |     % |
|----------+-------+---------------+-------|
| train    |  2500 |          76.6 |  67.7 |
| act      |  5000 |           9.2 |  16.3 |
| env step |  5000 |           5.6 |   9.8 |
| add      |  5000 |           0.2 |   0.3 |
| reset    |   103 |          25.3 |   0.9 |
| eval     |     1 |       14150.1 |   5   |
| total(s) |     1 |         282.9 | 100   |
total time: 1:16:58
Mem info: used: 6.796 GB, avail: 133.942 GB, total: 156.060 GB
